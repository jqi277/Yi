# fastapi_app.py  (runtime v3.7.7, analysis logic v3.7.2, refined combo & status/suggestion)
import os, base64, json, logging, traceback, re
from typing import Dict, Any, List

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, Response
from fastapi.middleware.cors import CORSMiddleware

from openai import OpenAI

RUNTIME_VERSION = "3.7.7"
ANALYSIS_VERSION = os.getenv("ANALYSIS_VERSION", "372").strip()  # default 372
SCHEMA_ID = "selfy.v3"
DEBUG = str(os.getenv("DEBUG","0")).strip() in ("1","true","True","YES","yes")

logging.basicConfig(level=logging.DEBUG if DEBUG else logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("selfy-ai")

app = FastAPI(title="Selfy AI - YiJing Analysis API", version=RUNTIME_VERSION)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# OpenAI client
try:
    client = OpenAI()
except Exception as e:
    logger.error("OpenAI client init failed: %s", e); client=None

BAGUA_SYMBOLS = {"ËâÆ":"Â±±","Á¶ª":"ÁÅ´","ÂÖë":"Ê≥Ω","‰πæ":"Â§©","Âù§":"Âú∞","Èúá":"Èõ∑","Â∑Ω":"È£é","Âùé":"Ê∞¥"}

# ---------------- helpers ----------------
def _to_data_url(content: bytes, content_type: str) -> str:
    return f"data:{content_type};base64,{base64.b64encode(content).decode('utf-8')}"

def _build_tools_schema() -> List[Dict[str, Any]]:
    return [{
      "type":"function",
      "function":{
        "name":"submit_analysis_v3",
        "description":"Return end-user facing JSON for Selfy AI YiJing analysis.",
        "parameters":{
          "type":"object",
          "properties":{
            "summary":{"type":"string"},
            "archetype":{"type":"string"},
            "confidence":{"type":"number"},
            "sections":{"type":"object","properties":{"ÂßøÊÄÅ":{"type":"string"},"Á•ûÊÉÖ":{"type":"string"},"Èù¢Áõ∏":{"type":"string"}},"required":["ÂßøÊÄÅ","Á•ûÊÉÖ","Èù¢Áõ∏"],"additionalProperties":False},
            "domains":{"type":"array","items":{"type":"string"}},
            "meta":{"type":"object","additionalProperties":True}
          },
          "required":["summary","archetype","confidence","sections","domains"],
          "additionalProperties":False
        }
      }
    }]

def _json_hint() -> str:
    return ("Âè™‰ª• JSON object ËøîÂõûÔºàÂøÖÈ°ª JSONÔºâ„ÄÇÁ§∫‰æã:{\"summary\":\"‚Ä¶\",\"archetype\":\"‚Ä¶\",\"confidence\":0.9,"
            "\"sections\":{\"ÂßøÊÄÅ\":\"‚Ä¶\",\"Á•ûÊÉÖ\":\"‚Ä¶\",\"Èù¢Áõ∏\":\"‚Ä¶\"},"
            "\"domains\":[\"ÈáëÈí±‰∏é‰∫ã‰∏ö\",\"ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ\"],"
            "\"meta\":{\"triple_analysis\":{\"ÂßøÊÄÅ\":{\"ËØ¥Êòé\":\"‚Ä¶\",\"Âç¶Ë±°\":\"ËâÆ\",\"Ëß£ËØª\":\"‚Ä¶\",\"ÊÄßÊ†ºÂÄæÂêë\":\"‚Ä¶\"},\"Á•ûÊÉÖ\":{‚Ä¶},\"Èù¢ÂÆπ\":{‚Ä¶},\"ÁªÑÂêàÊÑèÂ¢É\":\"‚Ä¶\",\"ÊÄªÁªì\":\"‚Ä¶\"},"
            "\"face_parts\":{\"Áúâ\":{\"ÁâπÂæÅ\":\"‚Ä¶\",\"Âç¶Ë±°\":\"‚Ä¶\",\"Ëß£ËØª\":\"‚Ä¶\"},\"Áúº\":{‚Ä¶},\"Èºª\":{‚Ä¶},\"Âò¥\":{‚Ä¶},\"È¢ß/‰∏ãÂ∑¥\":{‚Ä¶}},"
            "\"domains_detail\":{\"ÈáëÈí±‰∏é‰∫ã‰∏ö\":\"‚Ä¶(60‚Äì90Â≠ó)\",\"ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ\":\"‚Ä¶(60‚Äì90Â≠ó)\"}}}")

def _prompt_for_image_v372():
    sys = (
      "‰Ω†ÊòØ Selfy AI ÁöÑÊòìÁªèËßÇÁõ∏Âä©ÊâãÔºàv3.7.2 È£éÊ†ºÔºâ„ÄÇ"
      "‰∏•Ê†ºÊåâ‚Äú‰∏âË±°ÂõõÊÆµÂºè‚ÄùÂàÜÊûêÔºö„ÄêÂßøÊÄÅ/Á•ûÊÉÖ/Èù¢ÂÆπ„Äë‰∏âÈÉ®ÂàÜ„ÄÇÊØèÈÉ®ÂàÜÂøÖÈ°ªÂåÖÂê´Ôºö"
      "1) ËØ¥ÊòéÔºö1Âè•ÔºåÂÆ¢ËßÇÊèèÁªòÂ§ñËßÇ/Âä®‰Ωú/Ê∞îË¥®Ôºõ"
      "2) Âç¶Ë±°Ôºö‰ªÖÂÜô‰∏Ä‰∏™Âç¶ÂêçÔºàËâÆ/Á¶ª/ÂÖë/‰πæ/Âù§/Èúá/Â∑Ω/ÂùéÔºâÔºõ"
      "3) Ëß£ËØªÔºö1‚Äì2Âè•ÔºåÂü∫‰∫éÂç¶Ë±°‰∏éËßÇÂØüÂÅöÂê´‰πâÈòêÈáäÔºõ"
      "4) ÊÄßÊ†ºÂÄæÂêëÔºö1‚Äì2Âè•ÔºåÁã¨Á´ãÊàêÊÆµÔºå‰∏çË¶Å‰∏é‚ÄúËß£ËØª‚ÄùÈáçÂ§çÊé™Ëæû„ÄÇ"
      "ÁÑ∂ÂêéÁªôÂá∫Ôºö"
      "5) Âç¶Ë±°ÁªÑÂêàÔºöÊ†áÈ¢ò=‰∏âË±°Âç¶ÂêçÁõ∏Âä†ÔºàÂ¶Ç‚ÄúËâÆ + Á¶ª + ÂÖë‚ÄùÔºâÔºåÊ≠£Êñá 90‚Äì150 Â≠óÔºàÂèØ‰∏é‰∏âË±°ÁªìËÆ∫ÈÄÇÂ∫¶ÈáçÂêàÔºâÔºõ"
      "6) ÊÄªÁªìÊÄßÊ†ºÂç∞Ë±°Ôºö20‚Äì40Â≠óÔºåÈÅøÂÖçÊ®°ÊùøÂåñÔºõ"
      "7) ‰∫∫Ê†ºÊ†áÁ≠æ archetypeÔºö2‚Äì5Â≠ó‰∏≠ÊñáÔºåÂ¶Ç‚ÄúÂ§ñÂÜ∑ÂÜÖÁÉ≠/‰∏ªÂØºÂûã/Ë∞®ÊÖéÂûã‚Äù„ÄÇ"
      "Èù¢Áõ∏ÈúÄÊãÜÊàê‰∫îÂÆòÔºöÂú® meta.face_parts ‰∏≠ÔºåÁªô„ÄêÁúâ/Áúº/Èºª/Âò¥/È¢ß/‰∏ãÂ∑¥„ÄëÔºà‰ªªÈÄâ5È°πË¶ÜÁõñÔºâÂêÑÂÜô‚ÄúÁâπÂæÅÔºàÂ§ñËßÇÔºâ‚Äù‰∏é‚ÄúËß£ËØªÔºàÂü∫‰∫éÊòìÁªèÔºâ‚Äù„ÄÇ"
      "domains ‰ªÖ‰ªé ['ÈáëÈí±‰∏é‰∫ã‰∏ö','ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ'] ÈÄâÊã©ÔºõÂú® meta.domains_detail ‰∏≠ÂàÜÂà´ÂÜô 60‚Äì90 Â≠óÂª∫ËÆÆÊñáÊú¨„ÄÇ"
      "Â∞ÜÁªìÊûúÈÄöËøá submit_analysis_v3 Â∑•ÂÖ∑ËøîÂõûÔºåÂπ∂"+_json_hint()+"„ÄÇËØ≠Ë®ÄÔºö‰∏≠Êñá„ÄÇÊú¨Ê∂àÊÅØÂê´‚ÄúJSON‚Äù‰ª•Êª°Ë∂≥ API Ë¶ÅÊ±Ç„ÄÇ"
    )
    user = "ËØ∑Êåâ 3.7.2 È£éÊ†ºÂàÜÊûêÂõæÁâáÔºå‰∏•Ê†ºÈÄöËøáÂáΩÊï∞ËøîÂõû JSONÔºà‰∏çË¶ÅËæìÂá∫Ëá™Áî±ÊñáÊú¨Ôºâ„ÄÇ"
    return [{"role":"system","content":sys},{"role":"user","content":user}]

def _inflate_dotted_keys(obj: Dict[str, Any]) -> Dict[str, Any]:
    if not isinstance(obj, dict): return obj
    out: Dict[str, Any] = {}
    for k,v in obj.items():
        if "." not in k:
            out[k] = _inflate_dotted_keys(v) if isinstance(v, dict) else v
    for k,v in obj.items():
        if isinstance(k, str) and "." in k:
            head, tail = k.split(".", 1)
            base = out.setdefault(head, {})
            if not isinstance(base, dict): base = {}; out[head] = base
            cur = base
            parts = tail.split(".")
            for i, p in enumerate(parts):
                if i == len(parts)-1:
                    cur[p] = v
                else:
                    cur = cur.setdefault(p, {})
    for k in list(out.keys()):
        if isinstance(out[k], dict):
            out[k] = _inflate_dotted_keys(out[k])
    return out

def _call_openai(messages):
    return client.chat.completions.create(
        model="gpt-4o",
        temperature=0.4,
        tools=_build_tools_schema(),
        tool_choice={"type":"function","function":{"name":"submit_analysis_v3"}},
        response_format={"type":"json_object"},
        messages=messages
    )

def _insight_for_domains(hexes: List[str]) -> Dict[str, str]:
    s = set([h for h in hexes if h])
    biz = []
    if "‰πæ" in s or "Èúá" in s: biz.append("Êé®ËøõÂäõÂº∫„ÄÅÁõÆÊ†áÊÑüÊòéÁ°Æ")
    if "Âù§" in s or "ËâÆ" in s: biz.append("Á®≥ÂÅ•Âä°ÂÆû„ÄÅÊâßË°åÂà∞‰Ωç")
    if "Á¶ª" in s or "ÂÖë" in s: biz.append("Ë°®ËææÂçè‰ΩúÈ°∫ÁïÖ„ÄÅÂñÑ‰∫éÂΩ±Âìç")
    if "Âùé" in s: biz.append("È£éÈô©ÊÑèËØÜËæÉÂº∫„ÄÅËäÇÂ•èÊõ¥Á®≥")
    if "Â∑Ω" in s: biz.append("ÊìÖÂçèË∞ÉËµÑÊ∫ê„ÄÅÂñÑÊï¥Âêà")
    love = []
    if "ÂÖë" in s: love.append("‰∫íÂä®‰∫≤Âíå„ÄÅÊ≤üÈÄöËá™ÁÑ∂")
    if "Âù§" in s: love.append("ÈáçÊâøËØ∫‰∏éÂåÖÂÆπ")
    if "Á¶ª" in s: love.append("Ë°®ËææÊ∏ÖÊô∞„ÄÅÂñÑ‰∫éÂÖ±ÊÉÖ")
    if "Âùé" in s: love.append("ÂÆâÂÖ®ÊÑüÈúÄÊ±ÇÂÅèÈ´ò„ÄÅËæÉÊïèÊÑü")
    if "Èúá" in s or "‰πæ" in s: love.append("‰∏ªÂä®Èù†Ëøë„ÄÅÂÜ≥Êñ≠ÂäõËæÉÂº∫")
    return {"‰∫ã‰∏ö": "Ôºõ".join(biz), "ÊÑüÊÉÖ": "Ôºõ".join(love)}

def _merge_status_and_detail(status: str, detail: str) -> str:
    detail_first = detail.split("„ÄÇ")[0].strip() if detail else ""
    if detail_first:
        detail_first = re.sub(r"^(‰Ω†|‰ªñ|Â•π|Âú®‰∫ã‰∏ö‰∏ä|Âú®ÊÑüÊÉÖ‰∏≠|ÂÖ∂|ÂØπÊñπ|ÁõÆÂâç|ËøëÊúü)[Ôºå„ÄÅÔºö ]*", "", detail_first)
    parts = [p for p in [status, detail_first] if p]
    return "Ôºõ".join(parts)

def _imperative_suggestion(detail: str) -> str:
    if not detail: return ""
    text = detail
    replacements = [
        (r"ÈÄÇÂêà", "ÂèØ‰ºòÂÖàËÄÉËôë"),
        (r"ÂèØ‰ª•ËÄÉËôë", "ÂèØËÄÉËôë"),
        (r"ÈúÄË¶Å", "Âª∫ËÆÆÈáçÁÇπ"),
        (r"Â∫îÂΩì", "Âª∫ËÆÆ"),
        (r"ËÉΩÂ§ü", "ÂèØ"),
        (r"ÂèØËÉΩ‰ºö", "ÁïôÊÑèÂèØËÉΩ"),
        (r"ÊúâÂä©‰∫é", "‰ª•‰æø"),
    ]
    for pat, rep in replacements:
        text = re.sub(pat, rep, text)
    return text

def _collect_and_trim_traits(ta: Dict[str,Any]) -> (List[str], Dict[str,Any]):
    traits = []
    new_ta = {}
    for k in ["ÂßøÊÄÅ","Á•ûÊÉÖ","Èù¢ÂÆπ"]:
        o = (ta.get(k) or {}).copy()
        tend = (o.get("ÊÄßÊ†ºÂÄæÂêë") or "").strip()
        if tend:
            traits.append(tend)
            o["ÊÄßÊ†ºÂÄæÂêë"] = ""  # Ê∏ÖÁ©∫ÁªôÂâçÁ´ØÔºåÈÅøÂÖçÈáçÂ§ç
        new_ta[k] = o
    for k in ta.keys():
        if k not in new_ta:
            new_ta[k] = ta[k]
    return traits, new_ta

def _coerce_output_v372(data: Dict[str,Any]) -> Dict[str,Any]:
    data = _inflate_dotted_keys(data)
    out = dict(data)
    meta = out.get("meta") or {}
    if not isinstance(meta, dict): meta = {}
    out["meta"] = meta

    ta = meta.get("triple_analysis") or {}
    traits, ta = _collect_and_trim_traits(ta)
    meta["triple_analysis"] = ta

    hexes = [(ta.get("ÂßøÊÄÅ") or {}).get("Âç¶Ë±°",""),
             (ta.get("Á•ûÊÉÖ") or {}).get("Âç¶Ë±°",""),
             (ta.get("Èù¢ÂÆπ") or {}).get("Âç¶Ë±°","")]
    combo_title = " + ".join([h for h in hexes if h])
    if combo_title:
        meta["combo_title"] = combo_title

    one = (ta.get("ÊÄªÁªì") or out.get("summary","")).strip()
    traits_text = "Ôºõ".join([t for t in traits if t])
    if traits_text:
        if one and not one.endswith("„ÄÇ"): one += "„ÄÇ"
        one = (one or "") + traits_text
    meta["overview_card"] = {
        "title": f"üîÆ Âç¶Ë±°ÁªÑÂêàÔºö{combo_title}" if combo_title else "üîÆ Âç¶Ë±°ÁªÑÂêà",
        "summary": one
    }

    def _title(section: str, key: str) -> str:
        hx = (ta.get(key) or {}).get("Âç¶Ë±°","")
        sym = BAGUA_SYMBOLS.get(hx,"")
        return f"{section} ‚Üí {hx}Âç¶Ôºà{sym}Ôºâ" if hx else section
    meta["sections_titles"] = {"ÂßøÊÄÅ":_title("ÂßøÊÄÅ","ÂßøÊÄÅ"), "Á•ûÊÉÖ":_title("Á•ûÊÉÖ","Á•ûÊÉÖ"), "Èù¢Áõ∏":_title("Èù¢Áõ∏","Èù¢ÂÆπ")}

    arch = (out.get("archetype") or "").strip()
    if arch and not any('\u4e00' <= ch <= '\u9fff' for ch in arch):
        s = set([h for h in hexes if h])
        if "‰πæ" in s and "ÂÖë" in s: arch = "‰∏ªÂØº¬∑‰∫≤ÂíåÂûã"
        elif "‰πæ" in s and "Á¶ª" in s: arch = "‰∏ªÂØº¬∑Ë°®ËææÂûã"
        elif "ËâÆ" in s and "Âù§" in s: arch = "Á®≥Èáç¬∑ÂåÖÂÆπÂûã"
        elif "Âùé" in s and "Á¶ª" in s: arch = "Ë∞®ÊÖé¬∑Ë°®ËææÂûã"
        elif "Èúá" in s and "ÂÖë" in s: arch = "Ë°åÂä®¬∑‰∫≤ÂíåÂûã"
        else: arch = "ÁªºÂêàÂûã"
        out["archetype"] = arch

    status = _insight_for_domains(hexes)
    dd = meta.get("domains_detail") or {}
    merged_status = {
        "‰∫ã‰∏ö": _merge_status_and_detail(status.get("‰∫ã‰∏ö",""), dd.get("ÈáëÈí±‰∏é‰∫ã‰∏ö","")),
        "ÊÑüÊÉÖ": _merge_status_and_detail(status.get("ÊÑüÊÉÖ",""), dd.get("ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ","")),
    }
    meta["domains_status"] = merged_status
    meta["domains_suggestion"] = {
        "‰∫ã‰∏ö": _imperative_suggestion(dd.get("ÈáëÈí±‰∏é‰∫ã‰∏ö","")),
        "ÊÑüÊÉÖ": _imperative_suggestion(dd.get("ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ",""))
    }

    try:
        out["confidence"] = float(out.get("confidence",0.0))
    except Exception:
        out["confidence"] = 0.0
    meta["headline"] = {"tag": out.get("archetype",""), "confidence": out["confidence"]}

    out["meta"] = meta
    return out

# ---------------- routes ----------------
@app.get("/health")
def health(): return {"status":"ok"}

@app.get("/", include_in_schema=False)
def root():
    return HTMLResponse("<h3>Selfy AI</h3><a href='/docs'>/docs</a> ¬∑ <a href='/mobile'>/mobile</a>")

@app.head("/", include_in_schema=False)
def root_head():
    return Response(status_code=200)

@app.get("/version")
def version(): return {"runtime":RUNTIME_VERSION,"analysis":ANALYSIS_VERSION,"schema":SCHEMA_ID,"debug":DEBUG}

@app.get("/mobile", include_in_schema=False)
def mobile():
    path = os.path.join(os.path.dirname(__file__), "index_mobile.html")
    try:
        html = open(path, "r", encoding="utf-8").read()
    except Exception as e:
        return HTMLResponse(f"<pre>index_mobile.html not found: {e}</pre>", status_code=500)
    return HTMLResponse(html)

def _call_gpt(messages):
    if client is None:
        raise RuntimeError("OpenAI client not initialized")
    return client.chat.completions.create(
        model="gpt-4o",
        temperature=0.4,
        tools=_build_tools_schema(),
        tool_choice={"type":"function","function":{"name":"submit_analysis_v3"}},
        response_format={"type":"json_object"},
        messages=messages
    )

def _call_gpt_tool_with_image(data_url: str) -> Dict[str,Any]:
    messages = _prompt_for_image_v372()
    messages[-1]["content"] = [
        {"type":"text","text":messages[-1]["content"]},
        {"type":"image_url","image_url":{"url":data_url}}
    ]
    resp = _call_gpt(messages)
    choice = resp.choices[0]
    tool_calls = getattr(choice.message, "tool_calls", None)
    if tool_calls:
        args = json.loads(tool_calls[0].function.arguments)
    else:
        content = getattr(choice.message, "content", None)
        if isinstance(content, str) and content.strip().startswith("{"):
            args = json.loads(content)
        else:
            raise RuntimeError("Model did not return tool_calls.")
    return {"tool_args": args, "oai_raw": resp if DEBUG else None}

@app.post("/upload")
async def upload(file: UploadFile = File(...)):
    try:
        if not file: raise HTTPException(400,"No file")
        ct = file.content_type or ""
        if not ct.startswith("image/"): raise HTTPException(415,f"Unsupported content type: {ct}")
        raw = await file.read()
        if not raw: raise HTTPException(400,"Empty file")
        if len(raw) > 15*1024*1024: raise HTTPException(413,"File too large (>15MB)")

        data_url = _to_data_url(raw, ct)
        logger.info("[UPLOAD] %s %dB %s", file.filename, len(raw), ct)

        result = _call_gpt_tool_with_image(data_url)
        tool_args = result["tool_args"]
        final_out = _coerce_output_v372(tool_args)

        if DEBUG:
            meta = final_out.setdefault("meta",{}).setdefault("debug",{})
            meta["file_info"]={"filename":file.filename,"content_type":ct,"size":len(raw)}
            try:
                meta["oai_choice_finish_reason"]=result["oai_raw"].choices[0].finish_reason
            except Exception:
                meta["oai_choice_finish_reason"]="n/a"

        return JSONResponse(content=final_out, status_code=200)
    except HTTPException as he:
        if DEBUG:
            return JSONResponse(status_code=he.status_code, content={"error":he.detail,"debug":{"trace":traceback.format_exc()}})
        raise
    except Exception as e:
        logging.exception("upload failed: %s", e)
        body={"error":"Internal Server Error"}
        if DEBUG: body["debug"]={"message":str(e),"trace":traceback.format_exc()}
        return JSONResponse(status_code=500, content=body)
