# fastapi_app.py  (runtime v3.9.0 ¬∑ YiJing inference)
# - Tri-image (ÂßøÊÄÅ/Á•ûÊÉÖ/Èù¢Áõ∏) stays intact from upstream (model v3.7.2 style)
# - NEW: Âç¶Ë±°ÁªÑÂêà(‰∏âÂêàË±°) = ‰∫∫Áâ©ÁîªÂÉèÔºà‰∏ª/ËæÖ/Âü∫ + ‰∫îË°åÁîüÂÖãÔºå‰∏•Á¶ÅÂª∫ËÆÆÂè£ÂêªÔºâ
# - NEW: ‰∫ã‰∏ö/ÊÑüÊÉÖ = ËøëÊúüÁä∂ÊÄÅ(bullets) + ËøëÊúüÂª∫ËÆÆ(bullets)ÔºåÂÆåÂÖ®ÊåâËØçÂ∫ì‰∏éÁîüÂÖãÊé®ÂØº
# - Lexicon hot-load: yijing_lexicon.json in same folder; reload on every request
# - Render-compatible; no external state required
import os, json, re, base64, logging, traceback
from typing import Any, Dict, List, Tuple

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, Response
from fastapi.middleware.cors import CORSMiddleware

from openai import OpenAI

RUNTIME_VERSION = "3.9.0"
ANALYSIS_VERSION = os.getenv("ANALYSIS_VERSION", "372")  # model prompt profile
SCHEMA_ID = "selfy.v3"
DEBUG = str(os.getenv("DEBUG","0")).strip() in ("1","true","True","YES","yes")

logging.basicConfig(level=logging.DEBUG if DEBUG else logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("selfy-ai")

app = FastAPI(title="Selfy AI ‚Äî YiJing Inference API", version=RUNTIME_VERSION)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

try:
    client = OpenAI()
except Exception as e:
    logger.error("OpenAI client init failed: %s", e); client=None

# --- Utils ---
BAGUA_SYMBOLS = {"ËâÆ":"Â±±","Á¶ª":"ÁÅ´","ÂÖë":"Ê≥Ω","‰πæ":"Â§©","Âù§":"Âú∞","Èúá":"Èõ∑","Â∑Ω":"È£é","Âùé":"Ê∞¥"}

def _to_data_url(content: bytes, content_type: str) -> str:
    return f"data:{content_type};base64,{base64.b64encode(content).decode('utf-8')}"

# --- Lexicon ---
def load_lexicon() -> Dict[str, Any]:
    """Hot-load lexicon every call. Must be placed next to this file."""
    path = os.path.join(os.path.dirname(__file__), "yijing_lexicon.json")
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.warning("Lexicon missing or invalid, using minimal fallback: %s", e)
        # Minimal fallback for safety
        return {
            "persona": {"‰πæ":"ÂàöÂÅ•Ëá™Âº∫","Âù§":"ÂéöÂæ∑ËΩΩÁâ©","Á¶ª":"ÊòéËæ®Ë°®Ëææ","ÂÖë":"‰∫≤Âíå‰∫§ÊµÅ","Èúá":"Ë°åÂä®ÂºÄÂ±Ä","Â∑Ω":"ÂçèË∞ÉÂÖ•ÂæÆ","Âùé":"Ë∞®ÊÖéÊ±ÇËØÅ","ËâÆ":"Ê≠¢ÂÆöÁ®≥ÂÆà"},
            "domains": {"career":{},"love":{}},
            "wuxing":{"‰πæ":"Èáë","ÂÖë":"Èáë","Á¶ª":"ÁÅ´","Èúá":"Êú®","Â∑Ω":"Êú®","Âùé":"Ê∞¥","ËâÆ":"Âúü","Âù§":"Âúü"},
            "sheng":{"Êú®":"ÁÅ´","ÁÅ´":"Âúü","Âúü":"Èáë","Èáë":"Ê∞¥","Ê∞¥":"Êú®"},
            "ke":{"Êú®":"Âúü","Âúü":"Ê∞¥","Ê∞¥":"ÁÅ´","ÁÅ´":"Èáë","Èáë":"Êú®"},
            "fuse":{"Áîü":"ÁâπË¥®‰∫íË°•ÔºåÊõ¥ÂÆπÊòìÂΩ¢ÊàêÂêàÂäõ","ÂÖã":"È£éÊ†ºÊúâÂÜ≤Á™ÅÔºåÈúÄË¶ÅÂÖàÂØπÈΩêÊñπÂºèÂÜçÊé®Ëøõ","ÊØî":"È£éÊ†º‰∏ÄËá¥Ôºå‰ºòÂäøË¢´ÊîæÂ§ßÔºåÂêåÊó∂Ë¶ÅÁïôÊÑèÁõ≤Âå∫","Âπ∂":"ÂêÑÊúâ‰æßÈáçÔºåÂàÜÂ∑•Ê∏ÖÊô∞Ôºå‰∫í‰∏çÂπ≤Êâ∞"},
            "rel_influence":{"career":{},"love":{}}
        }

# --- OpenAI tool schema ---
def _build_tools_schema():
    return [{
      "type":"function",
      "function":{
        "name":"submit_analysis_v3",
        "description":"Return end-user facing JSON for Selfy AI YiJing analysis.",
        "parameters":{
          "type":"object",
          "properties":{
            "summary":{"type":"string"},
            "archetype":{"type":"string"},
            "confidence":{"type":"number"},
            "sections":{"type":"object","properties":{"ÂßøÊÄÅ":{"type":"string"},"Á•ûÊÉÖ":{"type":"string"},"Èù¢Áõ∏":{"type":"string"}},"required":["ÂßøÊÄÅ","Á•ûÊÉÖ","Èù¢Áõ∏"],"additionalProperties":False},
            "domains":{"type":"array","items":{"type":"string"}},
            "meta":{"type":"object","additionalProperties":True}
          },
          "required":["summary","archetype","confidence","sections","domains"],
          "additionalProperties":False
        }
      }
    }]

def _prompt_for_image_v372():
    sys = (
      "‰Ω†ÊòØ Selfy AI ÁöÑÊòìÁªèËßÇÁõ∏Âä©ÊâãÔºàv3.7.2 È£éÊ†ºÔºâ„ÄÇ"
      "‰∏•Ê†ºÊåâ‚Äú‰∏âË±°ÂõõÊÆµÂºè‚ÄùÂàÜÊûêÔºö„ÄêÂßøÊÄÅ/Á•ûÊÉÖ/Èù¢ÂÆπ„Äë‰∏âÈÉ®ÂàÜ„ÄÇÊØèÈÉ®ÂàÜÂåÖÂê´Ôºö"
      "1) ËØ¥ÊòéÔºö1Âè•ÔºåÂÆ¢ËßÇÊèèÁªòÔºõ2) Âç¶Ë±°Ôºö‰ªÖÂÜô‰∏Ä‰∏™ÂÖ´Âç¶ÂêçÔºõ3) Ëß£ËØªÔºö1‚Äì2Âè•Ôºõ4) ÊÄßÊ†ºÂÄæÂêëÔºö1‚Äì2Âè•„ÄÇ"
      "ÈöèÂêéÔºö5) Âç¶Ë±°ÁªÑÂêàÔºà90‚Äì150Â≠óÔºâÔºõ6) ÊÄªÁªìÊÄßÊ†ºÂç∞Ë±°Ôºà20‚Äì40Â≠óÔºâÔºõ7) archetypeÔºà2‚Äì5Â≠óÔºâ„ÄÇ"
      "ÂêåÊó∂Âú® meta.face_parts ‰∏≠Áªô„ÄêÁúâ/Áúº/Èºª/Âò¥/È¢ß/‰∏ãÂ∑¥„ÄëÔºàË¶ÜÁõñ5È°πÔºâÁâπÂæÅ‰∏éËß£ËØª„ÄÇ"
      "domains ‰ªÖ‰ªé ['ÈáëÈí±‰∏é‰∫ã‰∏ö','ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ'] ÈÄâÊã©ÔºõÂú® meta.domains_detail ‰∏≠ÂêÑÂÜô 60‚Äì90 Â≠óÂª∫ËÆÆ„ÄÇ"
      "ÈÄöËøá submit_analysis_v3 Â∑•ÂÖ∑‰ª• JSON ËøîÂõûÔºå‰∏çË¶ÅËæìÂá∫Ëá™Áî±ÊñáÊú¨„ÄÇ"
    )
    user = "ËØ∑Êåâ 3.7.2 È£éÊ†ºÂØπÂõæÂÉèËøõË°åÂàÜÊûêÔºåÂπ∂‰∏•Ê†º‰ª•Â∑•ÂÖ∑ËøîÂõû JSON„ÄÇ"
    return [{"role":"system","content":sys},{"role":"user","content":user}]

def _call_oai(messages):
    if client is None:
        raise RuntimeError("OpenAI client not initialized")
    return client.chat.completions.create(
        model="gpt-4o",
        temperature=0.4,
        tools=_build_tools_schema(),
        tool_choice={"type":"function","function":{"name":"submit_analysis_v3"}},
        response_format={"type":"json_object"},
        messages=messages
    )

# --- Text cleaners ---
DOMAIN_LEADS = r"(Âú®(ÈáëÈí±‰∏é‰∫ã‰∏ö|ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ|‰∫ã‰∏ö|ÊÑüÊÉÖ)(ÊñπÈù¢|‰∏≠|Èáå)?|ÁõÆÂâç|ËøëÊúü|ÂΩì‰∏ã)"
_STOPWORDS = r"(ÂßøÊÄÅ|Á•ûÊÉÖ|Èù¢ÂÆπ|Êï¥‰Ωì|Ê∞îË¥®|ÂΩ¢Ë±°|Áªô‰∫∫‰ª•|‰∏ÄÁßç|‰ª•Âèä|Âπ∂‰∏î|ËÄå‰∏î|Êõ¥Êòæ|ÊòæÂæó|Â±ïÁé∞Âá∫|ÊµÅÈú≤Âá∫|ÈÄèÈú≤Âá∫)"
def _depronoun(s:str)->str:
    if not isinstance(s,str): return s
    s = re.sub(r"^(‰ªñ|Â•π|TA|‰Ω†|ÂØπÊñπ|ÂÖ∂)(ÁöÑ)?[Ôºå„ÄÅÔºö ]*", "", s.strip())
    s = re.sub(r"^(Âú®(‰∫ã‰∏ö|ÊÑüÊÉÖ|ÁîüÊ¥ª)[‰∏ä‰∏≠]|ÁõÆÂâç|ËøëÊúü)[Ôºå„ÄÅÔºö ]*", "", s)
    return s
def _neutralize(s:str)->str:
    if not isinstance(s,str): return s
    s = re.sub(r"(‰ªñ|Â•π|TA|ÂØπÊñπ|ÂÖ∂)(ÁöÑ)?", "", s.strip())
    s = re.sub(DOMAIN_LEADS + r"[Ôºå„ÄÅÔºö ]*", "", s)
    s = re.sub(r"(ÂèØËÉΩ|ÊàñËÆ∏|‰πüËÆ∏)[Ôºå„ÄÅ ]*", "", s)
    s = re.sub(r"[Ôºå,]{2,}", "Ôºå", s)
    s = re.sub(r"[Ôºõ;]{2,}", "Ôºõ", s)
    return s.strip("ÔºõÔºå„ÄÇ ")
def _canon_key(s:str)->str:
    if not isinstance(s,str): return ""
    k = re.sub(_STOPWORDS, "", s)
    k = re.sub(r"[ÁöÑÂú∞Âæó]", "", k); k = re.sub(r"\s+", "", k)
    return k
def _dedupe_smart(s:str)->str:
    if not isinstance(s,str): return s
    s = s.strip("„ÄÇÔºõÔºå,; ")
    sentences = re.split(r"[„ÄÇÔºÅÔºü]", s)
    out = []
    for sen in sentences:
        sen = sen.strip("Ôºå,;Ôºõ ")
        if not sen: continue
        parts = re.split(r"[Ôºå,Ôºõ;]", sen)
        seen, kept = set(), []
        for p in parts:
            t = p.strip(); 
            if not t: continue
            ck = _canon_key(t)
            if ck and ck not in seen:
                seen.add(ck); kept.append(t)
        out.append("Ôºå".join(kept))
    return "„ÄÇ".join(out) + ("„ÄÇ" if out else "")

# --- YiJing inference helpers ---
def _rel(el_a:str, el_b:str, sheng:Dict[str,str], ke:Dict[str,str])->str:
    if not el_a or not el_b: return "Âπ∂"
    if el_a == el_b: return "ÊØî"
    if sheng.get(el_a) == el_b: return "Áîü"
    if ke.get(el_a) == el_b: return "ÂÖã"
    return "Âπ∂"

def _synthesize_combo(lex:Dict[str,Any], h1:str, h2:str, h3:str)->str:
    """‰∏âÂêàË±°Ôºö‰∫∫Áâ©ÁîªÂÉèÔºàÊó†Âª∫ËÆÆÔºâ"""
    persona = lex.get("persona",{})
    wuxing  = lex.get("wuxing",{})
    sheng   = lex.get("sheng",{})
    ke      = lex.get("ke",{})
    fuse    = lex.get("fuse",{})
    parts = []
    for role,h in (("‰∏ª",h1),("ËæÖ",h2),("Âü∫",h3)):
        if not h: continue
        sym = BAGUA_SYMBOLS.get(h,"")
        per = persona.get(h,"")
        el  = wuxing.get(h,"")
        p = f"{role}{h}Ôºà{sym}Ôºå{el}ÔºâÔºå{per}" if per else f"{role}{h}Ôºà{sym}Ôºå{el}Ôºâ"
        parts.append(p)
    # relations
    r1 = _rel(wuxing.get(h1,""), wuxing.get(h2,""), sheng, ke) if h1 and h2 else ""
    r2 = _rel(wuxing.get(h3,""), wuxing.get(h1,""), sheng, ke) if h3 and h1 else ""
    r_texts = []
    if r1: r_texts.append(f"‰∏ª‰∏éËæÖÔºö{fuse.get(r1,'')}")
    if r2: r_texts.append(f"Âü∫‰∏é‰∏ªÔºö{fuse.get(r2,'')}")
    out = "Ôºõ".join(parts) + "„ÄÇ" + " ".join([t for t in r_texts if t])
    # Âéª‚ÄúËøôÁ±ª‰∫∫/ËøôÁßç‰∫∫‚ÄùÁ±ªÊåá‰ª£ÔºöÊú¨ÊÆµÂè™ÈôàËø∞ÁâπË¥®
    return _dedupe_smart(_neutralize(_depronoun(out)))

def _collect_bullets(source: Dict[str,Any], keys: List[str], limit:int=4)->List[str]:
    seen, bullets = set(), []
    for k in keys:
        arr = (source.get(k) or {}).get("state") if isinstance(source.get(k), dict) else None
        if not arr: continue
        for item in arr:
            t = _dedupe_smart(_neutralize(_depronoun(str(item)))).strip("„ÄÇ")
            ck = _canon_key(t)
            if ck and ck not in seen:
                seen.add(ck); bullets.append("¬∑ " + t)
            if len(bullets) >= limit: break
        if len(bullets) >= limit: break
    return bullets

def _collect_advices(source: Dict[str,Any], keys: List[str], limit:int=3)->List[str]:
    seen, bullets = set(), []
    for k in keys:
        arr = (source.get(k) or {}).get("advice") if isinstance(source.get(k), dict) else None
        if not arr: continue
        for item in arr:
            t = _dedupe_smart(_neutralize(_depronoun(str(item)))).strip("„ÄÇ")
            ck = _canon_key(t)
            if ck and ck not in seen:
                seen.add(ck); bullets.append("¬∑ " + t)
            if len(bullets) >= limit: break
        if len(bullets) >= limit: break
    return bullets

def _relation_influence(lex:Dict[str,Any], domain:str, el_main:str, el_fu:str, el_base:str)->List[str]:
    sheng, ke = lex.get("sheng",{}), lex.get("ke",{})
    rel_text = lex.get("rel_influence",{}).get(domain,{})
    bullets = []
    if el_main and el_fu:
        r1 = _rel(el_main, el_fu, sheng, ke)
        if rel_text.get(r1): bullets.append("¬∑ " + rel_text[r1])
    if el_base and el_main:
        r2 = _rel(el_base, el_main, sheng, ke)
        if rel_text.get(r2): bullets.append("¬∑ " + rel_text[r2])
    # de-dup
    seen, out = set(), []
    for b in bullets:
        ck = _canon_key(b)
        if ck not in seen:
            seen.add(ck); out.append(b)
    return out[:2]

def _make_domains(lex:Dict[str,Any], h1:str, h2:str, h3:str)->Dict[str,Dict[str,List[str]]]:
    doms = {"career":{}, "love":{}}
    el = lex.get("wuxing",{})
    keys = [k for k in [h1,h2,h3] if k]
    for domain in ["career","love"]:
        source = lex.get("domains",{}).get(domain,{}) or {}
        status = _collect_bullets(source, keys, limit=4)
        status += _relation_influence(lex, domain, el.get(h1,""), el.get(h2,""), el.get(h3,""))
        # re-trim to <=4
        status = status[:4]
        advice = _collect_advices(source, keys, limit=3)
        doms[domain] = {"status": status, "advice": advice}
    return doms

# --- Post-processing of model output ---
def _combine_sentence(desc:str, interp:str)->str:
    if not desc and not interp: return ""
    desc  = _neutralize(_depronoun((desc or "").strip().rstrip("Ôºõ;„ÄÇ")))
    interp = _neutralize(_depronoun((interp or "").strip().lstrip("‚Äî‚Äî").lstrip("- ").strip().rstrip("Ôºõ;„ÄÇ")))
    interp = re.sub(r"^(ËøôÁßç|Ê≠§Á±ª|ËøôÁ±ª|ÂÖ∂|ËøôÁßçÂßøÊÄÅ|ËøôÁßçÁ•ûÊÉÖ|ËøôÁßçÈù¢ÂÆπ)[Ôºå„ÄÅÔºö ]*", "", interp)
    s = f"{desc}Ôºå{interp}" if (desc and interp) else (desc or interp)
    s = re.sub(r"[Ôºõ;]+", "Ôºõ", s); s = re.sub(r"ÔºåÔºå+", "Ôºå", s)
    return _dedupe_smart(s)

def _coerce_output(tool_args: Dict[str,Any])->Dict[str,Any]:
    out = dict(tool_args)
    meta = out.get("meta") or {}
    if not isinstance(meta, dict): meta = {}
    out["meta"] = meta

    # Merge triple analysis parts
    ta = meta.get("triple_analysis") or {}
    def _apply(o):
        desc = (o.get("ËØ¥Êòé") or ""); inter = (o.get("Ëß£ËØª") or "")
        merged = _combine_sentence(desc, inter)
        o["Ëß£ËØª"] = merged; return o
    for k in ["ÂßøÊÄÅ","Á•ûÊÉÖ","Èù¢ÂÆπ"]:
        if isinstance(ta.get(k), dict): ta[k] = _apply(ta[k])
    meta["triple_analysis"] = ta

    # Trio hexes
    h1 = (ta.get("ÂßøÊÄÅ") or {}).get("Âç¶Ë±°","") or ""
    h2 = (ta.get("Á•ûÊÉÖ") or {}).get("Âç¶Ë±°","") or ""
    h3 = (ta.get("Èù¢ÂÆπ") or {}).get("Âç¶Ë±°","") or ""

    # Load lexicon and synthesize
    lex = load_lexicon()
    combo_title = " + ".join([h for h in [h1,h2,h3] if h])
    combo_summary = _synthesize_combo(lex, h1, h2, h3)
    meta["overview_card"] = {"title": f"üîÆ Âç¶Ë±°ÁªÑÂêàÔºö{combo_title}" if combo_title else "üîÆ Âç¶Ë±°ÁªÑÂêà",
                             "summary": combo_summary}

    doms = _make_domains(lex, h1, h2, h3)
    meta["domains_status"] = {"‰∫ã‰∏ö": "\n".join(doms["career"]["status"]),
                              "ÊÑüÊÉÖ": "\n".join(doms["love"]["status"])}
    meta["domains_suggestion"] = {"‰∫ã‰∏ö": "\n".join(doms["career"]["advice"]),
                                  "ÊÑüÊÉÖ": "\n".join(doms["love"]["advice"])}

    # Headline
    try:
        conf = float(out.get("confidence",0.0))
    except Exception: conf = 0.0
    meta["headline"] = {"tag": (out.get("archetype") or "").strip(), "confidence": conf}

    # Top-level clean
    def _clean(s):
        if not isinstance(s,str): return s
        s = s.replace("‚Äî‚Äî","Ôºå")
        s = re.sub(r"[Ôºõ;]+","Ôºõ", s)
        s = re.sub(r"Ôºõ([„ÄÇÔºÅ])", r"\1", s)
        s = re.sub(r"([„ÄÇÔºÅÔºü])Ôºõ", r"\1", s)
        s = _depronoun(s); s = _neutralize(s)
        return _dedupe_smart(s)
    out["summary"] = _clean(out.get("summary",""))
    out["archetype"] = _clean(out.get("archetype",""))
    # deep clean meta
    def _deep(x):
        if isinstance(x, dict): return {k:_deep(v) for k,v in x.items()}
        if isinstance(x, list): return [_deep(v) for v in x]
        return _clean(x)
    out["meta"] = _deep(meta)
    return out

# --- Routes ---
@app.get("/health")
def health(): return {"status":"ok"}

@app.get("/", include_in_schema=False)
def root():
    return HTMLResponse("<h3>Selfy AI</h3><a href='/docs'>/docs</a> ¬∑ <a href='/mobile'>/mobile</a>")

@app.get("/version")
def version(): return {"runtime":RUNTIME_VERSION,"analysis":ANALYSIS_VERSION,"schema":SCHEMA_ID,"debug":DEBUG}

@app.get("/mobile", include_in_schema=False)
def mobile():
    path = os.path.join(os.path.dirname(__file__), "index_mobile.html")
    try:
        html = open(path, "r", encoding="utf-8").read()
    except Exception as e:
        return HTMLResponse(f"<pre>index_mobile.html not found: {e}</pre>", status_code=500)
    return HTMLResponse(html)

@app.post("/upload")
async def upload(file: UploadFile = File(...)):
    try:
        if not file: raise HTTPException(400,"No file")
        ct = file.content_type or ""
        if not ct.startswith("image/"): raise HTTPException(415,f"Unsupported content type: {ct}")
        raw = await file.read()
        if not raw: raise HTTPException(400,"Empty file")
        if len(raw) > 15*1024*1024: raise HTTPException(413,"File too large (>15MB)")

        data_url = _to_data_url(raw, ct)
        logger.info("[UPLOAD] %s %dB %s", file.filename, len(raw), ct)

        msgs = _prompt_for_image_v372()
        msgs[-1]["content"] = [
            {"type":"text","text":msgs[-1]["content"]},
            {"type":"image_url","image_url":{"url":data_url}}
        ]
        resp = _call_oai(msgs)
        choice = resp.choices[0]
        tool_calls = getattr(choice.message, "tool_calls", None)
        if tool_calls:
            args = json.loads(tool_calls[0].function.arguments)
        else:
            content = getattr(choice.message, "content", None)
            if isinstance(content, str) and content.strip().startswith("{"):
                args = json.loads(content)
            else:
                raise RuntimeError("Model did not return tool_calls.")
        final_out = _coerce_output(args)

        if DEBUG:
            final_out.setdefault("meta",{}).setdefault("debug",{})["oai_finish"] = resp.choices[0].finish_reason

        return JSONResponse(content=final_out, status_code=200)
    except HTTPException as he:
        if DEBUG:
            return JSONResponse(status_code=he.status_code, content={"error":he.detail,"debug":{"trace":traceback.format_exc()}})
        raise
    except Exception as e:
        logging.exception("upload failed: %s", e)
        body={"error":"Internal Server Error"}
        if DEBUG: body["debug"]={"message":str(e),"trace":traceback.format_exc()}
        return JSONResponse(status_code=500, content=body)
