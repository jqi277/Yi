# fastapi_app.py  (v3.5+ui)
import os
import base64
import json
import logging
import traceback
from typing import Dict, Any, List

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, Response
from fastapi.middleware.cors import CORSMiddleware

from openai import OpenAI

VERSION = "3.5"
SCHEMA_ID = "selfy.v3"
DEBUG = str(os.getenv("DEBUG", "0")).strip() in ("1", "true", "True", "YES", "yes")

logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("selfy-ai")

app = FastAPI(title="Selfy AI - YiJing Analysis API", version=VERSION)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"] if DEBUG else ["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

try:
    client = OpenAI()
except Exception as e:
    logger.error("OpenAI client init failed: %s", e)
    client = None


# ===== Bagua mapping =====
BAGUA_SYMBOLS = {
    "ËâÆ": "Â±±",
    "Á¶ª": "ÁÅ´",
    "ÂÖë": "Ê≥Ω",
    "‰πæ": "Â§©",
    "Âù§": "Âú∞",
    "Èúá": "Èõ∑",
    "Â∑Ω": "È£é",
    "Âùé": "Ê∞¥",
}


@app.get("/health")
def health():
    return {"status": "ok"}


@app.get("/", include_in_schema=False)
def root():
    return HTMLResponse(
        """
        <h3>Selfy AI - YiJing Analysis API</h3>
        <ul>
          <li><a href="/docs">/docs (Swagger)</a></li>
          <li><a href="/health">/health</a></li>
          <li><a href="/version">/version</a></li>
        </ul>
    """
    )


@app.head("/", include_in_schema=False)
def root_head():
    return Response(status_code=200)


@app.get("/version")
def version():
    return {"version": VERSION, "debug": DEBUG, "schema": SCHEMA_ID}


def _to_data_url(content: bytes, content_type: str) -> str:
    b64 = base64.b64encode(content).decode("utf-8")
    return f"data:{content_type};base64,{b64}"


def _build_tools_schema() -> List[Dict[str, Any]]:
    return [
        {
            "type": "function",
            "function": {
                "name": "submit_analysis_v3",
                "description": "Return end-user facing JSON for Selfy AI YiJing analysis.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "summary": {"type": "string"},
                        "archetype": {"type": "string"},
                        "confidence": {"type": "number"},
                        "sections": {
                            "type": "object",
                            "properties": {
                                "ÂßøÊÄÅ": {"type": "string"},
                                "Á•ûÊÉÖ": {"type": "string"},
                                "Èù¢Áõ∏": {"type": "string"},
                            },
                            "required": ["ÂßøÊÄÅ", "Á•ûÊÉÖ", "Èù¢Áõ∏"],
                            "additionalProperties": False,
                        },
                        "domains": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Only from ['ÈáëÈí±‰∏é‰∫ã‰∏ö','ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ']",
                        },
                        "meta": {
                            "type": "object",
                            "description": "Optional metadata for debugging or triple-analysis rich content",
                            "additionalProperties": True,
                        },
                    },
                    "required": [
                        "summary",
                        "archetype",
                        "confidence",
                        "sections",
                        "domains",
                    ],
                    "additionalProperties": False,
                },
            },
        }
    ]


def _prompt_for_image() -> List[Dict[str, Any]]:
    sys = (
        "‰Ω†ÊòØ Selfy AI ÁöÑÊòìÁªèËßÇÁõ∏Âä©Êâã„ÄÇÂøÖÈ°ªÂÖàÁî®‚Äú‰∏âË±°ÂõõÊÆµÂºè‚ÄùÂàÜÊûêÔºö"
        "„ÄêÂßøÊÄÅ/Á•ûÊÉÖ/Èù¢ÂÆπ„Äë‰∏âÈÉ®ÂàÜÔºåÊØèÈÉ®ÂàÜÂåÖÂê´Ôºö"
        "1) ËØ¥ÊòéÔºö1Âè•ÔºåÊèèÁªòËØ•Èù¢ÂêëÁöÑÂÖ∑‰ΩìÂ§ñËßÇ/Âä®‰Ωú/Ê∞îË¥®Ôºõ"
        "2) Âç¶Ë±°Ôºö‰ªÖÂÜô‰∏Ä‰∏™Âç¶ÂêçÔºàÂ¶Ç ËâÆ„ÄÅÁ¶ª„ÄÅÂÖë„ÄÅ‰πæ„ÄÅÂù§„ÄÅÈúá„ÄÅÂ∑Ω„ÄÅÂùéÔºâÔºõ"
        "3) Ëß£ËØªÔºö1‚Äì2Âè•ÔºåËß£ÈáäËØ•Âç¶Âú®Ê≠§Èù¢ÂêëÁöÑÂê´‰πâÔºõ"
        "4) ÊÄßÊ†ºÂÄæÂêëÔºö1‚Äì2Âè•ÔºåÊää‚ÄúÁâπÂæÅ‚ÄùÂêàÂπ∂ÊàêÂÄæÂêëÔºåÊÄªÁªìÊÄßÊ†ºËµ∞Âêë„ÄÇ"
        "ÁÑ∂ÂêéÁªôÂá∫Ôºö"
        "5) Âç¶Ë±°ÁªÑÂêàÔºöÊ†áÈ¢ò=‰∏âË±°Âç¶ÂêçÁõ∏Âä†ÔºàÂ¶Ç‚ÄúËâÆ + Á¶ª + ÂÖë‚ÄùÔºâÔºåÊ≠£Êñá90‚Äì150Â≠óÔºõ"
        "6) ÊÄªÁªìÊÄßÊ†ºÂç∞Ë±°Ôºö20‚Äì40Â≠óÁöÑÊÑèÂ¢ÉÂåñÊÄªÁªì„ÄÇ"
        "Â∞ÜÁªìÊûúÈÄöËøá submit_analysis_v3 Â∑•ÂÖ∑ËøîÂõûÔºåÂ≠óÊÆµË¶ÅÊ±ÇÔºö"
        "- summaryÔºöÁ¨¨6Êù°‚ÄúÊÄªÁªìÊÄßÊ†ºÂç∞Ë±°‚ÄùÔºõ"
        "- archetypeÔºöÊÑèÂ¢ÉÂåñÊ†áÁ≠æÔºàÂ¶Ç‚ÄúÂ§ñÂÜ∑ÂÜÖÁÉ≠‚ÄùÁ≠âÔºâÔºõ"
        "- sectionsÔºöÊää‰∏âË±°ÂêÑÂéãÊàê‰∏ÄÂè•‰∏≠ÊñáÔºàÂßøÊÄÅ/Á•ûÊÉÖ/Èù¢Áõ∏ÔºâÔºõ"
        "- domainsÔºö‰ªÖ‰ªé ['ÈáëÈí±‰∏é‰∫ã‰∏ö','ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ'] ÈÄâÊã©Ôºõ"
        "- meta.triple_analysisÔºöÈúÄÂåÖÂê´ÈîÆÔºö'ÂßøÊÄÅ','Á•ûÊÉÖ','Èù¢ÂÆπ','ÁªÑÂêàÊÑèÂ¢É','ÊÄªÁªì'Ôºõ"
        "  ÂÖ∂‰∏≠ÊØè‰∏™‰∏âË±°ÂØπË±°Âê´Ôºö'ËØ¥Êòé','Âç¶Ë±°','Ëß£ËØª','ÊÄßÊ†ºÂÄæÂêë'Ôºõ"
        "- meta.domains_detailÔºöÂØπ'ÈáëÈí±‰∏é‰∫ã‰∏ö'‰∏é'ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ'ÂàÜÂà´ÁªôÂá∫60‚Äì90Â≠óÂª∫ËÆÆÔºõ"
        "Á¶ÅÊ≠¢‰ΩøÁî®‚ÄúÁéØÂ¢É‚Äù‰Ωú‰∏∫Á¨¨‰∏âË±°„ÄÇËØ≠Ë®ÄÔºö‰∏≠Êñá„ÄÇÁ¶ÅÊ≠¢ËæìÂá∫Èô§Â∑•ÂÖ∑Ë∞ÉÁî®‰ª•Â§ñÁöÑ‰ªª‰ΩïËá™Áî±ÊñáÊú¨„ÄÇ"
        "ÂÖ´Âç¶ÂèÇËÄÉÔºöËâÆ=Ê≠¢=Á®≥Èáç/ËæπÁïåÔºõÁ¶ª=ÁÅ´=Êòé‰∫Æ/Ë°®ËææÔºõÂÖë=Ê≥Ω=‰∫§ÊµÅ/ÊÑâÊÇ¶Ôºõ‰πæ=Â§©=È¢ÜÂØº/Ëá™‰ø°ÔºõÂù§=Âú∞=ÂåÖÂÆπ/ÊâøËΩΩÔºõÈúá=Èõ∑=Ë°åÂä®ÔºõÂ∑Ω=È£é=ÂçèÂïÜÔºõÂùé=Ê∞¥=Ë∞®ÊÖé/Ê∑±Â∫¶„ÄÇ"
    )
    user = (
        "ËØ∑ÂàÜÊûêËøôÂº†ÂõæÁâáÔºåÁªìÂêàÊòìÁªè/Èù¢Áõ∏/‰∫îÂÆòÂÖ≥Á≥ª„ÄÇ"
        "ËøîÂõû‰∏•Ê†ºÁ¨¶Âêà schema ÁöÑÂ∑•ÂÖ∑ JSONÔºåÂπ∂ÂåÖÂê´ meta.triple_analysisÔºàÂßøÊÄÅ/Á•ûÊÉÖ/Èù¢ÂÆπÂõõÊÆµÂºè„ÄÅÁªÑÂêàÊÑèÂ¢É„ÄÅÊÄªÁªìÔºâ‰∏é meta.domains_detail„ÄÇ"
    )
    return [
        {"role": "system", "content": sys},
        {"role": "user", "content": user},
    ]


def _call_gpt_tool_with_image(data_url: str) -> Dict[str, Any]:
    if client is None:
        raise RuntimeError("OpenAI client is not initialized. Check OPENAI_API_KEY.")

    messages = _prompt_for_image()
    messages[-1]["content"] = [
        {"type": "text", "text": messages[-1]["content"]},
        {"type": "image_url", "image_url": {"url": data_url}},
    ]

    logger.debug("[OAI] Sending messages with image (Data URL)")

    resp = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.3,
        tools=_build_tools_schema(),
        tool_choice={"type": "function", "function": {"name": "submit_analysis_v3"}},
        response_format={"type": "json_object"},
        messages=messages,
    )

    if DEBUG:
        try:
            logger.debug("[OAI] raw response (pass1): %s", resp)
        except Exception:
            pass

    choice = resp.choices[0]
    tool_calls = getattr(choice.message, "tool_calls", None)

    if tool_calls:
        tool = tool_calls[0]
        if tool.function.name != "submit_analysis_v3":
            raise RuntimeError(f"Unexpected tool called: {tool.function.name}")
        try:
            args = json.loads(tool.function.arguments)
        except json.JSONDecodeError as e:
            raise RuntimeError(f"Tool arguments JSON decode failed: {e}")
        return {"tool_args": args, "oai_raw": resp if DEBUG else None}

    content = getattr(choice.message, "content", None)
    if isinstance(content, str) and content.strip().startswith("{"):
        try:
            args = json.loads(content)
            return {"tool_args": args, "oai_raw": resp if DEBUG else None}
        except Exception:
            pass

    harder_messages = messages + [
        {
            "role": "system",
            "content": "‰Ω†ÂøÖÈ°ªÈÄöËøáÂáΩÊï∞ submit_analysis_v3 ËøîÂõûÁªìÊûúÔºå‰∏•Ê†ºÁ¨¶Âêà schema„ÄÇ‰∏çË¶ÅÁõ¥Êé•ËæìÂá∫ÊñáÊú¨„ÄÇ",
        }
    ]
    resp2 = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.1,
        tools=_build_tools_schema(),
        tool_choice={"type": "function", "function": {"name": "submit_analysis_v3"}},
        response_format={"type": "json_object"},
        messages=harder_messages,
    )

    if DEBUG:
        try:
            logger.debug("[OAI] raw response (pass2): %s", resp2)
        except Exception:
            pass

    choice2 = resp2.choices[0]
    tool_calls2 = getattr(choice2.message, "tool_calls", None)
    if tool_calls2:
        tool2 = tool_calls2[0]
        try:
            args2 = json.loads(tool2.function.arguments)
        except json.JSONDecodeError as e:
            raise RuntimeError(f"Tool arguments JSON decode failed (pass2): {e}")
        return {"tool_args": args2, "oai_raw": resp2 if DEBUG else None}

    raise RuntimeError("Model did not return tool_calls after forced attempt.")


def _join_cn(items: List[str]) -> str:
    items = [s for s in items if isinstance(s, str) and s.strip()]
    if not items:
        return ""
    return "„ÄÅ".join(items)


def _coerce_output(data: Dict[str, Any]) -> Dict[str, Any]:
    allowed_domains = {"ÈáëÈí±‰∏é‰∫ã‰∏ö", "ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ"}

    out = dict(data)
    meta = out.get("meta") or {}
    if not isinstance(meta, dict):
        meta = {}
    out["meta"] = meta

    sections = out.get("sections") or {}
    if not isinstance(sections, dict):
        sections = {}

    ta = meta.get("triple_analysis") if isinstance(meta.get("triple_analysis"), dict) else {}

    def _mk_line(name_cn: str, fallback_key: str) -> str:
        o = ta.get(name_cn) or {}
        desc = o.get("ËØ¥Êòé") or ""
        hexg = o.get("Âç¶Ë±°") or ""
        mean = o.get("Ëß£ËØª") or ""
        tend = o.get("ÊÄßÊ†ºÂÄæÂêë") or ""
        parts = [p for p in [desc, f"Âç¶Ë±°Ôºö{hexg}" if hexg else "", mean, tend] if p]
        line = "Ôºõ".join(parts)
        return line or (sections.get(fallback_key) or "")

    sections["ÂßøÊÄÅ"] = _mk_line("ÂßøÊÄÅ", "ÂßøÊÄÅ")
    sections["Á•ûÊÉÖ"] = _mk_line("Á•ûÊÉÖ", "Á•ûÊÉÖ")
    sections["Èù¢Áõ∏"] = _mk_line("Èù¢ÂÆπ", "Èù¢Áõ∏")
    out["sections"] = sections

    detail_bucket = meta.setdefault("sections_detail", {})
    for k in ["ÂßøÊÄÅ", "Á•ûÊÉÖ", "Èù¢Áõ∏"]:
        v = sections.get(k)
        if isinstance(v, dict):
            detail_bucket[k] = v
            features = v.get("features") if isinstance(v.get("features"), list) else []
            features_txt = _join_cn(features)
            parts = []
            if features_txt:
                parts.append(f"ÁâπÂæÅÔºö{features_txt}")
            if v.get("hexagram"):
                parts.append(f"Âç¶Ë±°Ôºö{v.get('hexagram')}")
            if v.get("meaning"):
                parts.append(f"Âê´‰πâÔºö{v.get('meaning')}")
            if v.get("advice"):
                parts.append(f"Âª∫ËÆÆÔºö{v.get('advice')}")
            sections[k] = "Ôºõ".join([p for p in parts if p])
    out["sections"] = sections

    domains = out.get("domains")
    if isinstance(domains, dict):
        domain_keys = [k for k in domains.keys() if k in allowed_domains]
        out["domains"] = domain_keys
        meta["domains_detail"] = {k: domains[k] for k in domain_keys}
    elif isinstance(domains, list):
        out["domains"] = [d for d in domains if d in allowed_domains]
    else:
        out["domains"] = []

    out["summary"] = out.get("summary") or ""
    out["archetype"] = out.get("archetype") or ""
    try:
        out["confidence"] = float(out.get("confidence", 0.0))
    except Exception:
        out["confidence"] = 0.0

    if not isinstance(meta.get("triple_analysis"), dict):
        sd = meta.get("sections_detail") or {}
        if isinstance(sd, dict) and any(isinstance(sd.get(x), dict) for x in ["ÂßøÊÄÅ", "Á•ûÊÉÖ", "Èù¢Áõ∏"]):
            def _mk(sd_key):
                segd = sd.get(sd_key) or {}
                return {
                    "ËØ¥Êòé": "",
                    "Âç¶Ë±°": segd.get("hexagram", ""),
                    "ÁâπÂæÅ": segd.get("features", []),
                    "Ëß£ËØª": segd.get("meaning", ""),
                    "ÊÄßÊ†ºÂÄæÂêë": segd.get("advice", ""),
                }

            meta["triple_analysis"] = {
                "ÂßøÊÄÅ": _mk("ÂßøÊÄÅ"),
                "Á•ûÊÉÖ": _mk("Á•ûÊÉÖ"),
                "Èù¢ÂÆπ": _mk("Èù¢Áõ∏"),
                "ÁªÑÂêàÊÑèÂ¢É": "",
                "ÊÄªÁªì": out.get("summary", ""),
            }

    ta2 = meta.get("triple_analysis") or {}
    hexes = [
        ta2.get("ÂßøÊÄÅ", {}).get("Âç¶Ë±°", ""),
        ta2.get("Á•ûÊÉÖ", {}).get("Âç¶Ë±°", ""),
        ta2.get("Èù¢ÂÆπ", {}).get("Âç¶Ë±°", ""),
    ]
    combo_title = " + ".join([h for h in hexes if h])
    if combo_title:
        meta["combo_title"] = combo_title

    # === Build UI helpers for frontend ===

    # 1) È°∂ÈÉ® tagÔºöÊÄßÊ†ºÊ†áÁ≠æ + ÂèØ‰ø°Â∫¶
    meta["headline"] = {
        "tag": out.get("archetype", ""),
        "confidence": out.get("confidence", 0.0),
    }

    # 2) ÂàÜË±°Ê†áÈ¢òÔºöÊòæÁ§∫‚ÄúÂßøÊÄÅ ‚Üí ËâÆÂç¶ÔºàÂ±±Ôºâ‚ÄùÁ≠â
    def _title_with_hex(section_key: str, ta_key: str):
        hexname = (ta2.get(ta_key, {}) or {}).get("Âç¶Ë±°", "")
        symbol = BAGUA_SYMBOLS.get(hexname, "")
        if hexname and symbol:
            return f"{section_key} ‚Üí {hexname}Âç¶Ôºà{symbol}Ôºâ"
        elif hexname:
            return f"{section_key} ‚Üí {hexname}Âç¶"
        else:
            return section_key

    meta["sections_titles"] = {
        "ÂßøÊÄÅ": _title_with_hex("ÂßøÊÄÅ", "ÂßøÊÄÅ"),
        "Á•ûÊÉÖ": _title_with_hex("Á•ûÊÉÖ", "Á•ûÊÉÖ"),
        "Èù¢Áõ∏": _title_with_hex("Èù¢Áõ∏", "Èù¢ÂÆπ"),
    }

    # 3) Âç¶Ë±°ÁªÑÂêàÔºöÊ†áÈ¢ò + Ë¶ÅÁÇπÔºà‰æõÁ¨¨‰∏ÄÊéí box ÂàóÂá∫Ôºâ
    combo_points = []
    for k in ("ÂßøÊÄÅ", "Á•ûÊÉÖ", "Èù¢ÂÆπ"):
        tend = (ta2.get(k, {}) or {}).get("ÊÄßÊ†ºÂÄæÂêë", "")
        if isinstance(tend, str) and tend.strip():
            combo_points.append(tend.strip())

    combo_yijing = (ta2.get("ÁªÑÂêàÊÑèÂ¢É", "") or "").strip()
    if combo_yijing:
        combo_points.append(combo_yijing)

    combo_title_txt = meta.get("combo_title", "").strip()
    combo_full_title = f"üîÆ Âç¶Ë±°ÁªÑÂêàÔºö{combo_title_txt}" if combo_title_txt else "üîÆ Âç¶Ë±°ÁªÑÂêà"

    meta["combo_detail"] = {
        "title": combo_full_title,
        "bullets": combo_points[:6],
    }

    # 4) ÊÄªÁªìÊÄßÊ†ºÔºöÂä†‰∏ÄË°åÊÑèÂ¢ÉÂè•
    h1 = (ta2.get("ÂßøÊÄÅ", {}) or {}).get("Âç¶Ë±°", "")
    h2 = (ta2.get("Á•ûÊÉÖ", {}) or {}).get("Âç¶Ë±°", "")
    h3 = (ta2.get("Èù¢ÂÆπ", {}) or {}).get("Âç¶Ë±°", "")
    s1, s2, s3 = BAGUA_SYMBOLS.get(h1, ""), BAGUA_SYMBOLS.get(h2, ""), BAGUA_SYMBOLS.get(h3, "")
    imagery = ""
    if s1 and s2 and s3:
        imagery = f"‚Äú{s1}‰∏≠Êúâ{s2}Ôºå{s2}Êò†{s3}Èù¢‚Äù"
    elif s1 and s2:
        imagery = f"‚Äú{s1}Êò†{s2}ÂÖâ‚Äù"
    elif s2 and s3:
        imagery = f"‚Äú{s2}ÁÖß{s3}ÂÆπ‚Äù"

    meta["summary_rich"] = {
        "lead": out.get("summary", ""),
        "imagery": f"Âú®ÊòìÁªèÊÑèÂ¢É‰∏≠ÔºåÂÉèÊòØ {imagery} ‚Äî‚Äî ÂÜÖËóèÂÖâËäíÔºåÊã©‰∫∫ËÄåËÄÄ„ÄÇ" if imagery else "",
    }

    out["meta"] = meta
    return out


@app.post("/upload")
async def upload(file: UploadFile = File(...)):
    try:
        if not file:
            raise HTTPException(status_code=400, detail="No file uploaded.")

        content_type = file.content_type or ""
        if not content_type.startswith("image/"):
            raise HTTPException(
                status_code=415, detail=f"Unsupported content type: {content_type}"
            )

        raw = await file.read()
        if not raw or len(raw) == 0:
            raise HTTPException(status_code=400, detail="Empty file.")

        if len(raw) > 15 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="File too large (>15MB).")

        data_url = _to_data_url(raw, content_type)
        logger.info("[UPLOAD] file=%s size=%d type=%s", file.filename, len(raw), content_type)

        result = _call_gpt_tool_with_image(data_url)
        tool_args = result["tool_args"]

        final_out = _coerce_output(tool_args)

        if DEBUG:
            meta = final_out.setdefault("meta", {})
            meta.setdefault("debug", {})
            meta["debug"]["debug_mode"] = True
            meta["debug"]["file_info"] = {
                "filename": file.filename,
                "content_type": content_type,
                "size": len(raw),
            }
            if result.get("oai_raw") is not None:
                try:
                    meta["debug"]["oai_choice_finish_reason"] = result["oai_raw"].choices[
                        0
                    ].finish_reason
                    meta["debug"]["oai_has_tool_calls"] = bool(
                        result["oai_raw"].choices[0].message.tool_calls
                    )
                except Exception:
                    meta["debug"]["oai_choice_finish_reason"] = "n/a"
                    meta["debug"]["oai_has_tool_calls"] = "n/a"

        return JSONResponse(content=final_out, status_code=200)

    except HTTPException as he:
        if DEBUG:
            return JSONResponse(
                status_code=he.status_code,
                content={"error": he.detail, "debug": {"trace": traceback.format_exc()}},
            )
        raise
    except Exception as e:
        logger.exception("[ERROR] /upload failed: %s", e)
        body = {"error": "Internal Server Error"}
        if DEBUG:
            body["debug"] = {"message": str(e), "trace": traceback.format_exc()}
        return JSONResponse(status_code=500, content=body)
