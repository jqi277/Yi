
# fastapi_app.py  (v3.7.2)
import os, base64, json, logging, traceback, statistics
from typing import Dict, Any, List

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, Response
from fastapi.middleware.cors import CORSMiddleware

from openai import OpenAI

VERSION = "3.7.2"
SCHEMA_ID = "selfy.v3"
DEBUG = str(os.getenv("DEBUG","0")).strip() in ("1","true","True","YES","yes")

logging.basicConfig(level=logging.DEBUG if DEBUG else logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("selfy-ai")

app = FastAPI(title="Selfy AI - YiJing Analysis API", version=VERSION)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

try:
    client = OpenAI()
except Exception as e:
    logger.error("OpenAI client init failed: %s", e); client=None

BAGUA_SYMBOLS = {"ËâÆ":"Â±±","Á¶ª":"ÁÅ´","ÂÖë":"Ê≥Ω","‰πæ":"Â§©","Âù§":"Âú∞","Èúá":"Èõ∑","Â∑Ω":"È£é","Âùé":"Ê∞¥"}
BAGUA_TRAITS = {"ËâÆ":"Á®≥Èáç/ÂÆöÁïå","Á¶ª":"ÊòéÊô∞/Ë°®Ëææ","ÂÖë":"‰∫≤Âíå/‰∫§ÊµÅ","‰πæ":"Ëá™‰ø°/‰∏ªÂØº","Âù§":"ÂåÖÂÆπ/ÊâøËΩΩ","Èúá":"ÊûúÊñ≠/Ë°åÂä®","Â∑Ω":"ÂúÜËûç/ÂçèÂïÜ","Âùé":"Ë∞®ÊÖé/Ê∑±ÊÄù"}

def _to_data_url(content: bytes, content_type: str) -> str:
    return f"data:{content_type};base64,{base64.b64encode(content).decode('utf-8')}"

def _build_tools_schema():
    return [{
      "type":"function",
      "function":{
        "name":"submit_analysis_v3",
        "description":"Return end-user facing JSON for Selfy AI YiJing analysis.",
        "parameters":{
          "type":"object",
          "properties":{
            "summary":{"type":"string"},
            "archetype":{"type":"string"},
            "confidence":{"type":"number"},
            "sections":{"type":"object","properties":{"ÂßøÊÄÅ":{"type":"string"},"Á•ûÊÉÖ":{"type":"string"},"Èù¢Áõ∏":{"type":"string"}},"required":["ÂßøÊÄÅ","Á•ûÊÉÖ","Èù¢Áõ∏"],"additionalProperties":False},
            "domains":{"type":"array","items":{"type":"string"}},
            "meta":{"type":"object","additionalProperties":True},
          },
          "required":["summary","archetype","confidence","sections","domains"],
          "additionalProperties":False
        }
      }
    }]

def _json_hint():
    return ("Âè™‰ª• JSON object ËøîÂõûÔºàÂøÖÈ°ª JSONÔºâ„ÄÇÁ§∫‰æã:{\"summary\":\"‚Ä¶\",\"archetype\":\"‚Ä¶\",\"confidence\":0.9,"
            "\"sections\":{\"ÂßøÊÄÅ\":\"‚Ä¶\",\"Á•ûÊÉÖ\":\"‚Ä¶\",\"Èù¢Áõ∏\":\"‚Ä¶\"},"
            "\"domains\":[\"ÈáëÈí±‰∏é‰∫ã‰∏ö\",\"ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ\"],"
            "\"meta\":{\"triple_analysis\":{\"ÂßøÊÄÅ\":{\"ËØ¥Êòé\":\"‚Ä¶\",\"Âç¶Ë±°\":\"ËâÆ\",\"Ëß£ËØª\":\"‚Ä¶ÔºàÂ∞ÜÊÄßÊ†ºÂÄæÂêëËá™ÁÑ∂ËûçÂÖ•Ëß£ËØªÂÜÖÔºâ\"},\"Á•ûÊÉÖ\":{‚Ä¶},\"Èù¢ÂÆπ\":{‚Ä¶},\"ÁªÑÂêàÊÑèÂ¢É\":\"‚Ä¶\",\"ÊÄªÁªì\":\"‚Ä¶\"},"
            "\"face_parts\":{\"Áúâ\":{\"ÁâπÂæÅ\":\"‚Ä¶\",\"Âç¶Ë±°\":\"‚Ä¶\",\"Ëß£ËØª\":\"‚Ä¶\"},\"Áúº\":{‚Ä¶},\"Èºª\":{‚Ä¶},\"Âò¥\":{‚Ä¶},\"È¢ß/‰∏ãÂ∑¥\":{‚Ä¶}},"
            "\"domains_detail\":{\"ÈáëÈí±‰∏é‰∫ã‰∏ö\":\"‚Ä¶\",\"ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ\":\"‚Ä¶\"}}}")

def _prompt_for_image():
    sys = (
      "‰Ω†ÊòØ Selfy AI ÁöÑÊòìÁªèËßÇÁõ∏Âä©Êâã„ÄÇ"
      "‰∏•Ê†ºÁî®‚Äú‰∏âË±°ÂõõÊÆµÂºè‚ÄùÂàÜÊûêÔºö„ÄêÂßøÊÄÅ/Á•ûÊÉÖ/Èù¢ÂÆπ„Äë„ÄÇÊØèÈÉ®ÂàÜÂê´ÔºöËØ¥Êòé(1Âè•)ÔºõÂç¶Ë±°(ËâÆ/Á¶ª/ÂÖë/‰πæ/Âù§/Èúá/Â∑Ω/Âùé)ÔºõËß£ËØª(1‚Äì3Âè•)ÔºõÊÄßÊ†ºÂÄæÂêë(1‚Äì2Âè•)„ÄÇ"
      "ÈáçË¶ÅÔºöÂú®ËæìÂá∫Êó∂ÔºåÊää‚ÄúÊÄßÊ†ºÂÄæÂêë‚ÄùËá™ÁÑ∂Âú∞**ËûçÂÖ•Ëß£ËØª**‰∏≠ÔºàËß£ËØªÂèØÁõ∏Â∫îÂä†ÈïøÔºâÔºåÂâçÁ´ØÂ∞Ü‰∏çÂçïÁã¨Â±ïÁ§∫‚ÄúÊÄßÊ†ºÂÄæÂêë‚ÄùÂ≠óÊÆµ„ÄÇ"
      "Èù¢Áõ∏ÂøÖÈ°ªÊãÜËß£‰∫îÂÆòÔºöÁªô„ÄêÁúâ/Áúº/Èºª/Âò¥/È¢ßÊàñ‰∏ãÂ∑¥„ÄëÂêÑ1Âè•ÂÖ∑‰ΩìÁâπÂæÅÔºåÂπ∂‰∏∫ÊØèÈ°πÊ†áÊ≥®‰∏Ä‰∏™Âç¶Ë±°Âπ∂Ëß£ËØªÔºåÂÜôÂÖ• meta.face_parts„ÄÇ"
      "ÁÑ∂ÂêéÔºö5) Âç¶Ë±°ÁªÑÂêàÔºöÂü∫‰∫é‰∏âÂç¶‚ÄúÁªºÂêàÊé®ÁêÜ‚ÄùÂÜô 4‚Äì6 Êù°Ë¶ÅÁÇπÔºà‰∏çÂæóÈÄêÂ≠óÈáçÂ§ç‰∏âË±°ÂéüÊñáÔºõË¶ÅÂêàÊàêÊñ∞ÁöÑÊ¥ûËßÅÔºåÂ¶ÇÂ§ñÂú®ÂëàÁé∞/ÂÜÖÂú®È©±Âä®/Ê≤üÈÄöÈ£éÊ†º/ÂÜ≥Á≠ñÈ£éÊ†º/È£éÈô©ÂÅèÂ•ΩÁ≠âÔºâÔºõ"
      "6) ÊÄªÁªìÊÄßÊ†ºÂç∞Ë±°Ôºö20‚Äì40Â≠óÔºåÂøÖÈ°ª‰∏é‰∏âÂç¶Âº∫Áõ∏ÂÖ≥ÔºåÈÅøÂÖçÊ®°ÊùøÂåñÔºõ"
      "7) ‰∫∫Ê†ºÊ†áÁ≠æ archetypeÔºöÊ†πÊçÆ‰∏âÂç¶‰∏ªË∞ÉËá™Âä®ÁîüÊàê„ÄÇ"
      "Êòé‰ª§Á¶ÅÊ≠¢ÔºöÂá∫Áé∞‚Äú‰∫îÂÆòÁ´ØÊ≠£/Êï¥‰ΩìÈù¢ÂÆπÂíåË∞ê/Èù¢ÂÆπÂíåË∞ê‚ÄùÁ≠âÂ•óËØùÔºõÂç¶Ë±°ÁªÑÂêà‰∏≠Á¶ÅÊ≠¢‰ªÖÂ§çÂà∂‰∏âË±°‚ÄòÊÄßÊ†ºÂÄæÂêë‚ÄôÂéüÂè•„ÄÇ"
      "Â∞ÜÁªìÊûúÈÄöËøá submit_analysis_v3 Â∑•ÂÖ∑ËøîÂõûÔºåÂπ∂"+_json_hint()+"„ÄÇËØ≠Ë®ÄÔºö‰∏≠Êñá„ÄÇÊú¨Ê∂àÊÅØÂê´‚ÄúJSON‚Äù‰ª•Êª°Ë∂≥ API Ë¶ÅÊ±Ç„ÄÇ"
    )
    user = "ËØ∑‰∏•Ê†ºÊåâË¶ÅÊ±ÇÂàÜÊûêÂõæÁâáÔºåÂπ∂Âè™‰ª• JSON Ê†ºÂºèÈÄöËøáÂáΩÊï∞ËøîÂõû„ÄÇ"
    return [{"role":"system","content":sys},{"role":"user","content":user}]

def _inflate_dotted_keys(obj):
    if not isinstance(obj, dict): return obj
    out = {}
    for k,v in obj.items():
        if "." not in k: out[k]=_inflate_dotted_keys(v) if isinstance(v,dict) else v
    for k,v in obj.items():
        if isinstance(k,str) and "." in k:
            head,tail=k.split(".",1)
            base = out.setdefault(head, {})
            if not isinstance(base, dict): base = {}; out[head]=base
            cur=base
            parts=tail.split(".")
            for i,p in enumerate(parts):
                if i==len(parts)-1: cur[p]=v
                else: cur=cur.setdefault(p,{})
    for k in list(out.keys()):
        if isinstance(out[k], dict): out[k]=_inflate_dotted_keys(out[k])
    return out

def _call_openai(messages):
    return client.chat.completions.create(
        model="gpt-4o",
        temperature=0.45,
        tools=_build_tools_schema(),
        tool_choice={"type":"function","function":{"name":"submit_analysis_v3"}},
        response_format={"type":"json_object"},
        messages=messages,
    )

def _synthesize_combo(ta):
    hexes = [(ta.get("ÂßøÊÄÅ") or {}).get("Âç¶Ë±°",""),
             (ta.get("Á•ûÊÉÖ") or {}).get("Âç¶Ë±°",""),
             (ta.get("Èù¢ÂÆπ") or {}).get("Âç¶Ë±°","")]
    bullets = []
    traits_map = {"ËâÆ":"Á®≥Èáç","Á¶ª":"Ë°®Ëææ","ÂÖë":"‰∫≤Âíå","‰πæ":"‰∏ªÂØº","Âù§":"ÂåÖÂÆπ","Èúá":"Ë°åÂä®","Â∑Ω":"ÂçèË∞É","Âùé":"Ë∞®ÊÖé"}
    traits = [traits_map.get(h,"") for h in hexes if h]
    if len(traits)>=2:
        bullets.append(f"Â§ñÂú®Ë°®Áé∞ÂÅè{traits[0]}ÔºåÂÜÖÂú®È©±Âä®Êõ¥{traits[1]}„ÄÇ")
    if "ÂÖë" in hexes:
        bullets.append("Ê≤üÈÄöÈ£éÊ†º‰∫≤ÂíåËÄåÁõ¥Êé•ÔºåÈáçËßÜÁúüÂÆû‰∏éÊÑâÊÇ¶ÁöÑ‰∫íÂä®„ÄÇ")
    if "Âùé" in hexes:
        bullets.append("ÂÜ≥Á≠ñÂâç‰ºöËØÑ‰º∞È£éÈô©‰∏éÂêéÊûúÔºåÂÅèÁ®≥ÂÅ•„ÄÇ")
    if "Èúá" in hexes:
        bullets.append("ÈÅá‰∫ãË°åÂä®ÊûúÊñ≠ÔºåÊé®ËøõËäÇÂ•èÂø´„ÄÇ")
    if "Á¶ª" in hexes:
        bullets.append("Ë°®ËææÊ∏ÖÊô∞ÔºåÊìÖÈïø‰ø°ÊÅØÊèêÁÇº‰∏éÂëàÁé∞„ÄÇ")
    if "‰πæ" in hexes:
        bullets.append("ÂÖ∑Â§á‰∏ªÂØºÊÄß‰∏éÁõÆÊ†áÊÑüÔºåÊÑøÊÑèÊâøÊãÖË¥£‰ªª„ÄÇ")
    if "Âù§" in hexes:
        bullets.append("Â§Ñ‰∫ãÂåÖÂÆπÁ®≥Â¶•ÔºåÂñÑ‰∫éÊâòÂ∫ï‰∏éÊâøËΩΩÂõ¢Èòü„ÄÇ")
    if "ËâÆ" in hexes:
        bullets.append("ÊúâËæπÁïåÊÑü‰∏éÁß©Â∫èÊÑüÔºåÂÅö‰∫ãÊ≤âÁ®≥ÂèØÈù†„ÄÇ")
    if "Â∑Ω" in hexes:
        bullets.append("ÂÄæÂêëÂçèÂïÜ‰∏éÊï¥ÂêàËµÑÊ∫êÔºåÂñÑÂÅöÂçèË∞ÉËÄÖ„ÄÇ")
    seen=set(); out=[]
    for b in bullets:
        if b not in seen: seen.add(b); out.append(b)
        if len(out)>=5: break
    return hexes, out

def _insight_for_domains(hexes):
    sets = set(hexes)
    lines = {}
    segs=[]
    if "‰πæ" in sets or "Èúá" in sets: segs.append("ÂÖ∑Êé®ËøõÂäõ‰∏éÁõÆÊ†áÊÑü")
    if "Âù§" in sets or "ËâÆ" in sets: segs.append("Á®≥ÂÅ•Â∫¶‰∏éÊâßË°åÂäõÂÖºÂ§á")
    if "Á¶ª" in sets or "ÂÖë" in sets: segs.append("ÊìÖË°®Ëææ‰∏éÂçè‰Ωú")
    if "Âùé" in sets: segs.append("È£éÈô©ÊÑèËØÜËæÉÂº∫")
    if "Â∑Ω" in sets: segs.append("ÂñÑ‰∫éÂçèË∞ÉËµÑÊ∫ê")
    lines["ÈáëÈí±‰∏é‰∫ã‰∏ö"]="Ôºõ".join(segs) if segs else "‰ª•Á®≥‰∏≠Ê±ÇËøõ‰∏∫‰∏ªÔºåÂÖºÈ°æÊ≤üÈÄö‰∏éÊâßË°å„ÄÇ"
    segs=[]
    if "ÂÖë" in sets: segs.append("‰∫íÂä®‰∫≤Âíå")
    if "Âù§" in sets: segs.append("ÈáçÊâøËØ∫‰∏éÂåÖÂÆπ")
    if "Á¶ª" in sets: segs.append("Ë°®ËææÊòéÁ°Æ")
    if "Âùé" in sets: segs.append("ÂÆâÂÖ®ÊÑüÈúÄÊ±ÇËæÉÈ´ò")
    if "Èúá" in sets or "‰πæ" in sets: segs.append("‰∏ªÂä®ËøΩÊ±Ç‰∏éÂÜ≥Êñ≠")
    lines["ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ"]="Ôºõ".join(segs) if segs else "ÈáçËßÜÁ®≥ÂÆöÂÖ≥Á≥ªÔºåÊ≤üÈÄöÁõ¥Êé•„ÄÇ"
    return lines

def _coerce_output(data: Dict[str,Any]) -> Dict[str,Any]:
    data = _inflate_dotted_keys(data)
    out = dict(data)
    meta = out.get("meta") or {}
    if not isinstance(meta, dict): meta = {}
    out["meta"]=meta

    ta = meta.get("triple_analysis") or {}

    hexes, synth_bullets = _synthesize_combo(ta)
    combo_title = " + ".join([h for h in hexes if h])
    if combo_title: meta["combo_title"]=combo_title

    lead = out.get("summary","")
    meta["overview_card"] = {"title": f"üîÆ Âç¶Ë±°ÁªÑÂêàÔºö{combo_title}" if combo_title else "üîÆ Âç¶Ë±°ÁªÑÂêà",
                             "summary": lead,
                             "bullets": synth_bullets}

    dd = meta.get("domains_detail") or {}
    insights = _insight_for_domains(hexes)
    meta["domains_insight"] = insights
    def _expand(txt, fallback):
        if not isinstance(txt,str) or len(txt)<80:
            return (fallback or "") + " ÂÄæÂêëÂ∞Ü‰ºòÂäøÂú∫ÊôØ‰∏éÈ£éÈô©ÁÇπÊàêÂØπÁÆ°ÁêÜÔºöÁî®‰ºòÂäøË¶ÜÁõñÂÖ≥ÈîÆËäÇÁÇπÔºåÂêåÊó∂ËÆæÁΩÆÊ£ÄÊü•ÁÇπ‰∏éÂèçÈ¶àÊú∫Âà∂Ôºå‰ª•‰øùËØÅËäÇÂ•è‰∏éË¥®Èáè„ÄÇ"
        return txt
    meta["domains_detail_long"]={
        "ÈáëÈí±‰∏é‰∫ã‰∏ö": _expand(dd.get("ÈáëÈí±‰∏é‰∫ã‰∏ö",""), "Âú®‰∫ã‰∏ö‰∏≠Âª∫ËÆÆÊää‰∏ªÂØºÊÄß‰∏éÁ®≥ÂÅ•Â∫¶ÁªìÂêàÔºåÂÖàÂÆöÊ∏ÖÊô∞ÁõÆÊ†á‰∏éËæπÁïåÔºåÂÜçÈÄêÊ≠•Êé®Ëøõ"),
        "ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ": _expand(dd.get("ÈÖçÂÅ∂‰∏éÊÑüÊÉÖ",""), "Âú®ÂÖ≥Á≥ª‰∏≠‰øùÊåÅÁúüËØöË°®Ëææ‰∏éÁ®≥Âõ∫ÊâøËØ∫ÔºåÂÖ≥Ê≥®ÂØπÊñπËäÇÂ•è‰∏éÈúÄÊ±ÇÂ∑ÆÂºÇÔºåËê•ÈÄ†ÂèØÈ¢ÑÊúüÁöÑÂÆâÂÖ®ÊÑü")
    }

    def _title_with_hex(section_key: str, ta_key: str):
        hexname = (ta.get(ta_key) or {}).get("Âç¶Ë±°","")
        symbol = {"ËâÆ":"Â±±","Á¶ª":"ÁÅ´","ÂÖë":"Ê≥Ω","‰πæ":"Â§©","Âù§":"Âú∞","Èúá":"Èõ∑","Â∑Ω":"È£é","Âùé":"Ê∞¥"}.get(hexname,"")
        return f"{section_key} ‚Üí {hexname}Âç¶Ôºà{symbol}Ôºâ" if hexname and symbol else (f"{section_key} ‚Üí {hexname}Âç¶" if hexname else section_key)
    meta["sections_titles"]={"ÂßøÊÄÅ":_title_with_hex("ÂßøÊÄÅ","ÂßøÊÄÅ"),"Á•ûÊÉÖ":_title_with_hex("Á•ûÊÉÖ","Á•ûÊÉÖ"),"Èù¢Áõ∏":_title_with_hex("Èù¢Áõ∏","Èù¢ÂÆπ")}

    arch = out.get("archetype") or ""
    out["archetype"]=arch
    try: out["confidence"]=float(out.get("confidence",0.0))
    except: out["confidence"]=0.0
    meta["headline"]={"tag":out["archetype"],"confidence":out["confidence"]}

    out["meta"]=meta
    return out

@app.get("/health")
def health(): return {"status":"ok"}

@app.get("/", include_in_schema=False)
def root():
    return HTMLResponse("<h3>Selfy AI</h3><a href='/docs'>/docs</a>")

@app.head("/", include_in_schema=False)
def root_head():
    return Response(status_code=200)

@app.get("/version")
def version(): return {"version":VERSION,"schema":SCHEMA_ID,"debug":DEBUG}

def _call_openai(messages):
    return client.chat.completions.create(
        model="gpt-4o",
        temperature=0.45,
        tools=_build_tools_schema(),
        tool_choice={"type":"function","function":{"name":"submit_analysis_v3"}},
        response_format={"type":"json_object"},
        messages=messages,
    )

def _call_gpt_tool_with_image(data_url: str) -> Dict[str,Any]:
    if client is None: raise RuntimeError("OpenAI client not initialized")
    messages = _prompt_for_image()
    messages[-1]["content"]=[{"type":"text","text":messages[-1]["content"]},{"type":"image_url","image_url":{"url":data_url}}]
    resp=_call_openai(messages)
    choice=resp.choices[0]
    tool_calls=getattr(choice.message,"tool_calls",None)
    if tool_calls:
        args=json.loads(tool_calls[0].function.arguments)
    else:
        content=getattr(choice.message,"content",None)
        if isinstance(content,str) and content.strip().startswith("{"):
            args=json.loads(content)
        else:
            raise RuntimeError("Model did not return tool_calls.")
    return {"tool_args":args, "oai_raw": resp if DEBUG else None}

@app.post("/upload")
async def upload(file: UploadFile = File(...)):
    try:
        if not file: raise HTTPException(400,"No file")
        ct=file.content_type or ""
        if not ct.startswith("image/"): raise HTTPException(415,f"Unsupported content type: {ct}")
        raw=await file.read()
        if not raw: raise HTTPException(400,"Empty file")
        if len(raw)>15*1024*1024: raise HTTPException(413,"File too large (>15MB)")

        data_url=_to_data_url(raw, ct)
        logger.info("[UPLOAD] %s %dB %s", file.filename, len(raw), ct)

        result=_call_gpt_tool_with_image(data_url)
        tool_args=result["tool_args"]

        final_out=_coerce_output(tool_args)

        if DEBUG:
            meta=final_out.setdefault("meta",{}).setdefault("debug",{})
            meta["file_info"]={"filename":file.filename,"content_type":ct,"size":len(raw)}
            try:
                meta["oai_choice_finish_reason"]=result["oai_raw"].choices[0].finish_reason
            except Exception:
                meta["oai_choice_finish_reason"]="n/a"

        return JSONResponse(content=final_out, status_code=200)
    except HTTPException as he:
        if DEBUG: return JSONResponse(status_code=he.status_code, content={"error":he.detail,"debug":{"trace":traceback.format_exc()}})
        raise
    except Exception as e:
        logging.exception("upload failed: %s", e)
        body={"error":"Internal Server Error"}
        if DEBUG: body["debug"]={"message":str(e),"trace":traceback.format_exc()}
        return JSONResponse(status_code=500, content=body)
