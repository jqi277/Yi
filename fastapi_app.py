# fastapi_app.py  (v3.6-ui-plus)
import os
import base64
import json
import logging
import traceback
from typing import Dict, Any, List

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, Response
from fastapi.middleware.cors import CORSMiddleware

from openai import OpenAI

VERSION = "3.6"
SCHEMA_ID = "selfy.v3"
DEBUG = str(os.getenv("DEBUG", "0")).strip() in ("1", "true", "True", "YES", "yes")

logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("selfy-ai")

app = FastAPI(title="Selfy AI - YiJing Analysis API", version=VERSION)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"] if DEBUG else ["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

try:
    client = OpenAI()
except Exception as e:
    logger.error("OpenAI client init failed: %s", e)
    client = None

# ===== Bagua mapping =====
BAGUA_SYMBOLS = {
    "è‰®": "å±±",
    "ç¦»": "ç«",
    "å…‘": "æ³½",
    "ä¹¾": "å¤©",
    "å¤": "åœ°",
    "éœ‡": "é›·",
    "å·½": "é£",
    "å": "æ°´",
}

BAGUA_TRAITS = {
    "è‰®": "ç¨³é‡/å®šç•Œ",
    "ç¦»": "æ˜æ™°/è¡¨è¾¾",
    "å…‘": "äº²å’Œ/äº¤æµ",
    "ä¹¾": "è‡ªä¿¡/ä¸»å¯¼",
    "å¤": "åŒ…å®¹/æ‰¿è½½",
    "éœ‡": "æœæ–­/è¡ŒåŠ¨",
    "å·½": "åœ†è/åå•†",
    "å": "è°¨æ…/æ·±æ€",
}


@app.get("/health")
def health():
    return {"status": "ok"}


@app.get("/", include_in_schema=False)
def root():
    return HTMLResponse(
        """
        <h3>Selfy AI - YiJing Analysis API</h3>
        <ul>
          <li><a href="/docs">/docs (Swagger)</a></li>
          <li><a href="/health">/health</a></li>
          <li><a href="/version">/version</a></li>
        </ul>
    """
    )


@app.head("/", include_in_schema=False)
def root_head():
    return Response(status_code=200)


@app.get("/version")
def version():
    return {"version": VERSION, "debug": DEBUG, "schema": SCHEMA_ID}


def _to_data_url(content: bytes, content_type: str) -> str:
    b64 = base64.b64encode(content).decode("utf-8")
    return f"data:{content_type};base64,{b64}"


def _build_tools_schema() -> List[Dict[str, Any]]:
    return [
        {
            "type": "function",
            "function": {
                "name": "submit_analysis_v3",
                "description": "Return end-user facing JSON for Selfy AI YiJing analysis.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "summary": {"type": "string"},
                        "archetype": {"type": "string"},
                        "confidence": {"type": "number"},
                        "sections": {
                            "type": "object",
                            "properties": {
                                "å§¿æ€": {"type": "string"},
                                "ç¥æƒ…": {"type": "string"},
                                "é¢ç›¸": {"type": "string"},
                            },
                            "required": ["å§¿æ€", "ç¥æƒ…", "é¢ç›¸"],
                            "additionalProperties": False,
                        },
                        "domains": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Only from ['é‡‘é’±ä¸äº‹ä¸š','é…å¶ä¸æ„Ÿæƒ…']",
                        },
                        "meta": {
                            "type": "object",
                            "description": "Optional metadata for debugging or rich content",
                            "additionalProperties": True,
                        },
                    },
                    "required": [
                        "summary","archetype","confidence","sections","domains"
                    ],
                    "additionalProperties": False,
                },
            },
        }
    ]


def _prompt_for_image() -> List[Dict[str, Any]]:
    sys = (
        "ä½ æ˜¯ Selfy AI çš„æ˜“ç»è§‚ç›¸åŠ©æ‰‹ã€‚"
        "å¿…é¡»å…ˆç”¨â€œä¸‰è±¡å››æ®µå¼â€åˆ†æï¼šã€å§¿æ€/ç¥æƒ…/é¢å®¹ã€‘ä¸‰éƒ¨åˆ†ï¼Œæ¯éƒ¨åˆ†åŒ…å«ï¼š"
        "1) è¯´æ˜ï¼š1å¥ï¼Œæç»˜è¯¥é¢å‘çš„å…·ä½“å¤–è§‚/åŠ¨ä½œ/æ°”è´¨ï¼›"
        "2) å¦è±¡ï¼šä»…å†™ä¸€ä¸ªå¦åï¼ˆè‰®/ç¦»/å…‘/ä¹¾/å¤/éœ‡/å·½/åï¼‰ï¼›"
        "3) è§£è¯»ï¼š1â€“2å¥ï¼Œè§£é‡Šè¯¥å¦åœ¨æ­¤é¢å‘çš„å«ä¹‰ï¼›"
        "4) æ€§æ ¼å€¾å‘ï¼š1â€“2å¥ï¼Œæ€»ç»“è¯¥é¢çš„æ€§æ ¼èµ°å‘ã€‚"
        "â€”â€” é¢ç›¸éƒ¨åˆ†éœ€â€œæ‹†è§£äº”å®˜â€ï¼Œç»™å‡ºã€çœ‰/çœ¼/é¼»/å˜´/é¢§æˆ–ä¸‹å·´ã€‘å„1å¥å…·ä½“ç‰¹å¾ï¼Œå¹¶åŸºäºæ˜“ç»ä½œè§£è¯»ï¼ˆæ˜ å°„åˆ°â€˜è‰®ç¦»å…‘ä¹¾å¤éœ‡å·½åâ€™ä¹‹ä¸€ï¼‰ï¼Œå½¢æˆ meta.face_partsã€‚"
        "ç„¶åç»™å‡ºï¼š"
        "5) å¦è±¡ç»„åˆï¼šæ ‡é¢˜=ä¸‰è±¡å¦åç›¸åŠ ï¼ˆå¦‚â€œè‰® + ç¦» + å…‘â€ï¼‰ï¼Œæ­£æ–‡ä¸º4â€“6æ¡è¦ç‚¹ï¼ˆç”¨çŸ­å¥ï¼‰ï¼Œé¿å…ç©ºæ³›ï¼›"
        "6) æ€»ç»“æ€§æ ¼å°è±¡ï¼š20â€“40å­—ï¼Œå¿…é¡»ç»“åˆä¸‰å¦ç‰¹å¾å½¢æˆâ€œç‹¬ç‰¹ä¸”ç›¸å…³â€çš„æ€»ç»“ï¼›"
        "7) äººæ ¼æ ‡ç­¾ archetypeï¼šå¿…é¡»æ ¹æ®ä¸‰å¦çš„ä¸»è°ƒè‡ªåŠ¨ç”Ÿæˆï¼ˆä¾‹å¦‚ ä¹¾+å¤â†’â€œå¤–åˆšå†…æŸ”â€ï¼Œè‰®+ç¦»â†’â€œå¤–ç¨³å†…æ˜â€ ç­‰ï¼‰ï¼Œç¦æ­¢ä½¿ç”¨å›ºå®šå¥—è¯ã€‚"
        "å°†ç»“æœé€šè¿‡ submit_analysis_v3 å·¥å…·è¿”å›ï¼Œå­—æ®µè¦æ±‚ï¼š"
        "- summaryï¼šç¬¬6æ¡â€œæ€»ç»“æ€§æ ¼å°è±¡â€ï¼›"
        "- archetypeï¼šç¬¬7æ¡ç”Ÿæˆçš„äººæ ¼æ ‡ç­¾ï¼›"
        "- sectionsï¼šä¸‰è±¡å„å‹æˆä¸€å¥ä¸­æ–‡ï¼ˆå§¿æ€/ç¥æƒ…/é¢ç›¸ï¼‰ï¼›"
        "- domainsï¼šä»…ä» ['é‡‘é’±ä¸äº‹ä¸š','é…å¶ä¸æ„Ÿæƒ…'] é€‰æ‹©ï¼›"
        "- meta.triple_analysisï¼šå«é”®'å§¿æ€','ç¥æƒ…','é¢å®¹','ç»„åˆæ„å¢ƒ','æ€»ç»“'ï¼›æ¯ä¸ªä¸‰è±¡å«'è¯´æ˜','å¦è±¡','è§£è¯»','æ€§æ ¼å€¾å‘'ï¼›"
        "- meta.face_partsï¼šé”®ä¸º'çœ‰','çœ¼','é¼»','å˜´','é¢§/ä¸‹å·´'ï¼Œæ¯ä¸ªå€¼å«'ç‰¹å¾','å¦è±¡','è§£è¯»'ï¼›"
        "- meta.domains_detailï¼šå¯¹'é‡‘é’±ä¸äº‹ä¸š'ä¸'é…å¶ä¸æ„Ÿæƒ…'åˆ†åˆ«ç»™å‡ºå°½é‡â€œå•è¡Œå¯è¯»â€çš„å»ºè®®ï¼ˆå„40â€“70å­—ï¼‰ã€‚"
        "è¯­è¨€ï¼šä¸­æ–‡ã€‚ç¦æ­¢è¾“å‡ºé™¤å·¥å…·è°ƒç”¨ä»¥å¤–çš„ä»»ä½•è‡ªç”±æ–‡æœ¬ã€‚"
    )
    user = (
        "è¯·ä¸¥æ ¼æŒ‰è¦æ±‚åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œé¿å…æ¨¡æ¿åŒ–æªè¾ã€‚"
    )
    return [{"role": "system", "content": sys}, {"role": "user", "content": user}]


def _call_gpt_tool_with_image(data_url: str) -> Dict[str, Any]:
    if client is None:
        raise RuntimeError("OpenAI client is not initialized. Check OPENAI_API_KEY.")

    messages = _prompt_for_image()
    messages[-1]["content"] = [
        {"type": "text", "text": messages[-1]["content"]},
        {"type": "image_url", "image_url": {"url": data_url}},
    ]

    logger.debug("[OAI] Sending messages with image (Data URL)")

    resp = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.4,  # æé«˜ä¸€ç‚¹å¤šæ ·æ€§
        tools=_build_tools_schema(),
        tool_choice={"type": "function", "function": {"name": "submit_analysis_v3"}},
        response_format={"type": "json_object"},
        messages=messages,
    )

    if DEBUG:
        try:
            logger.debug("[OAI] raw response (pass1): %s", resp)
        except Exception:
            pass

    choice = resp.choices[0]
    tool_calls = getattr(choice.message, "tool_calls", None)

    if tool_calls:
        tool = tool_calls[0]
        if tool.function.name != "submit_analysis_v3":
            raise RuntimeError(f"Unexpected tool called: {tool.function.name}")
        try:
            args = json.loads(tool.function.arguments)
        except json.JSONDecodeError as e:
            raise RuntimeError(f"Tool arguments JSON decode failed: {e}")
        return {"tool_args": args, "oai_raw": resp if DEBUG else None}

    content = getattr(choice.message, "content", None)
    if isinstance(content, str) and content.strip().startswith("{"):
        try:
            args = json.loads(content)
            return {"tool_args": args, "oai_raw": resp if DEBUG else None}
        except Exception:
            pass

    harder_messages = messages + [
        {"role": "system", "content": "ä½ å¿…é¡»é€šè¿‡å‡½æ•° submit_analysis_v3 è¿”å›ç»“æœï¼Œä¸¥æ ¼ç¬¦åˆ schemaã€‚ä¸è¦ç›´æ¥è¾“å‡ºæ–‡æœ¬ã€‚"}
    ]
    resp2 = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.35,
        tools=_build_tools_schema(),
        tool_choice={"type": "function", "function": {"name": "submit_analysis_v3"}},
        response_format={"type": "json_object"},
        messages=harder_messages,
    )

    if DEBUG:
        try:
            logger.debug("[OAI] raw response (pass2): %s", resp2)
        except Exception:
            pass

    choice2 = resp2.choices[0]
    tool_calls2 = getattr(choice2.message, "tool_calls", None)
    if tool_calls2:
        tool2 = tool_calls2[0]
        try:
            args2 = json.loads(tool2.function.arguments)
        except json.JSONDecodeError as e:
            raise RuntimeError(f"Tool arguments JSON decode failed (pass2): {e}")
        return {"tool_args": args2, "oai_raw": resp2 if DEBUG else None}

    raise RuntimeError("Model did not return tool_calls after forced attempt.")


def _join_cn(items: List[str]) -> str:
    items = [s for s in items if isinstance(s, str) and s.strip()]
    if not items:
        return ""
    return "ã€".join(items)


def _compose_auto_archetype(hexes: List[str]) -> str:
    # ä¾æ®ä¸‰å¦ä¸»è°ƒç»„åˆä¸€ä¸ªæ ‡ç­¾
    tags = [BAGUA_TRAITS.get(h, "") for h in hexes if h]
    tags = [t.split("/")[0] for t in tags if t]
    if not tags:
        return ""
    if len(tags) >= 2:
        return f"å¤–{tags[0]}å†…{tags[1]}"
    return f"{tags[0]}å–å‘"


def _coerce_output(data: Dict[str, Any]) -> Dict[str, Any]:
    allowed_domains = {"é‡‘é’±ä¸äº‹ä¸š", "é…å¶ä¸æ„Ÿæƒ…"}

    out = dict(data)
    meta = out.get("meta") or {}
    if not isinstance(meta, dict):
        meta = {}
    out["meta"] = meta

    sections = out.get("sections") or {}
    if not isinstance(sections, dict):
        sections = {}

    ta = meta.get("triple_analysis") if isinstance(meta.get("triple_analysis"), dict) else {}

    def _mk_line(name_cn: str, fallback_key: str) -> str:
        o = ta.get(name_cn) or {}
        desc = o.get("è¯´æ˜") or ""
        hexg = o.get("å¦è±¡") or ""
        mean = o.get("è§£è¯»") or ""
        tend = o.get("æ€§æ ¼å€¾å‘") or ""
        parts = [p for p in [desc, f"å¦è±¡ï¼š{hexg}" if hexg else "", mean, tend] if p]
        line = "ï¼›".join(parts)
        return line or (sections.get(fallback_key) or "")

    sections["å§¿æ€"] = _mk_line("å§¿æ€", "å§¿æ€")
    sections["ç¥æƒ…"] = _mk_line("ç¥æƒ…", "ç¥æƒ…")
    sections["é¢ç›¸"] = _mk_line("é¢å®¹", "é¢ç›¸")
    out["sections"] = sections

    # é¢ç›¸ç»†åˆ†ï¼ˆé€ä¼ ï¼‰
    face_parts = meta.get("face_parts")
    if not isinstance(face_parts, dict):
        meta["face_parts"] = {}

    domains = out.get("domains")
    if isinstance(domains, dict):
        domain_keys = [k for k in domains.keys() if k in allowed_domains]
        out["domains"] = domain_keys
        meta["domains_detail"] = {k: domains[k] for k in domain_keys}
    elif isinstance(domains, list):
        out["domains"] = [d for d in domains if d in allowed_domains]
    else:
        out["domains"] = []

    out["summary"] = out.get("summary") or ""
    # archetype è‹¥ç¼ºå¤±åˆ™è‡ªåŠ¨ç»„åˆä¸€ä¸ª
    try:
        out["confidence"] = float(out.get("confidence", 0.0))
    except Exception:
        out["confidence"] = 0.0

    if not out.get("archetype"):
        ta2 = meta.get("triple_analysis") or {}
        hexes = [
            ta2.get("å§¿æ€", {}).get("å¦è±¡", ""),
            ta2.get("ç¥æƒ…", {}).get("å¦è±¡", ""),
            ta2.get("é¢å®¹", {}).get("å¦è±¡", ""),
        ]
        out["archetype"] = _compose_auto_archetype(hexes)

    # combo title
    ta2 = meta.get("triple_analysis") or {}
    hexes = [
        ta2.get("å§¿æ€", {}).get("å¦è±¡", ""),
        ta2.get("ç¥æƒ…", {}).get("å¦è±¡", ""),
        ta2.get("é¢å®¹", {}).get("å¦è±¡", ""),
    ]
    combo_title = " + ".join([h for h in hexes if h])
    if combo_title:
        meta["combo_title"] = combo_title

    # === UI helpers ===
    meta["headline"] = {"tag": out.get("archetype", ""), "confidence": out.get("confidence", 0.0)}

    def _title_with_hex(section_key: str, ta_key: str):
        hexname = (ta2.get(ta_key, {}) or {}).get("å¦è±¡", "")
        symbol = BAGUA_SYMBOLS.get(hexname, "")
        if hexname and symbol:
            return f"{section_key} â†’ {hexname}å¦ï¼ˆ{symbol}ï¼‰"
        elif hexname:
            return f"{section_key} â†’ {hexname}å¦"
        else:
            return section_key

    meta["sections_titles"] = {
        "å§¿æ€": _title_with_hex("å§¿æ€", "å§¿æ€"),
        "ç¥æƒ…": _title_with_hex("ç¥æƒ…", "ç¥æƒ…"),
        "é¢ç›¸": _title_with_hex("é¢ç›¸", "é¢å®¹"),
    }

    # ç»„åˆè¦ç‚¹ï¼šä»æ€§æ ¼å€¾å‘æè¦ + ç»„åˆæ„å¢ƒ
    combo_points = []
    for k in ("å§¿æ€", "ç¥æƒ…", "é¢å®¹"):
        tend = (ta2.get(k, {}) or {}).get("æ€§æ ¼å€¾å‘", "")
        if isinstance(tend, str) and tend.strip():
            combo_points.append(tend.strip())
    combo_yijing = (ta2.get("ç»„åˆæ„å¢ƒ", "") or "").strip()
    if combo_yijing:
        combo_points.append(combo_yijing)

    combo_title_txt = meta.get("combo_title", "").strip()
    combo_full_title = f"ğŸ”® å¦è±¡ç»„åˆï¼š{combo_title_txt}" if combo_title_txt else "ğŸ”® å¦è±¡ç»„åˆ"
    meta["combo_detail"] = {"title": combo_full_title, "bullets": combo_points[:6]}

    # æ€»ç»“ + æ„å¢ƒ
    h1, h2, h3 = hexes + ["", "", ""][:max(0, 3 - len(hexes))]
    s1, s2, s3 = BAGUA_SYMBOLS.get(h1, ""), BAGUA_SYMBOLS.get(h2, ""), BAGUA_SYMBOLS.get(h3, "")
    imagery = ""
    if s1 and s2 and s3:
        imagery = f"â€œ{s1}ä¸­æœ‰{s2}ï¼Œ{s2}æ˜ {s3}é¢â€"
    elif s1 and s2:
        imagery = f"â€œ{s1}æ˜ {s2}å…‰â€"
    elif s2 and s3:
        imagery = f"â€œ{s2}ç…§{s3}å®¹â€"

    meta["summary_rich"] = {
        "lead": out.get("summary", ""),
        "imagery": f"åœ¨æ˜“ç»æ„å¢ƒä¸­ï¼Œåƒæ˜¯ {imagery} â€”â€” å†…è—å…‰èŠ’ï¼Œæ‹©äººè€Œè€€ã€‚" if imagery else "",
    }

    out["meta"] = meta
    return out


@app.post("/upload")
async def upload(file: UploadFile = File(...)):
    try:
        if not file:
            raise HTTPException(status_code=400, detail="No file uploaded.")

        content_type = file.content_type or ""
        if not content_type.startswith("image/"):
            raise HTTPException(
                status_code=415, detail=f"Unsupported content type: {content_type}"
            )

        raw = await file.read()
        if not raw or len(raw) == 0:
            raise HTTPException(status_code=400, detail="Empty file.")

        if len(raw) > 15 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="File too large (>15MB).")

        data_url = _to_data_url(raw, content_type)
        logger.info("[UPLOAD] file=%s size=%d type=%s", file.filename, len(raw), content_type)

        result = _call_gpt_tool_with_image(data_url)
        tool_args = result["tool_args"]

        final_out = _coerce_output(tool_args)

        if DEBUG:
            meta = final_out.setdefault("meta", {})
            meta.setdefault("debug", {})
            meta["debug"]["debug_mode"] = True
            meta["debug"]["file_info"] = {
                "filename": file.filename,
                "content_type": content_type,
                "size": len(raw),
            }
            if result.get("oai_raw") is not None:
                try:
                    meta["debug"]["oai_choice_finish_reason"] = result["oai_raw"].choices[0].finish_reason
                    meta["debug"]["oai_has_tool_calls"] = bool(result["oai_raw"].choices[0].message.tool_calls)
                except Exception:
                    meta["debug"]["oai_choice_finish_reason"] = "n/a"
                    meta["debug"]["oai_has_tool_calls"] = "n/a"

        return JSONResponse(content=final_out, status_code=200)

    except HTTPException as he:
        if DEBUG:
            return JSONResponse(
                status_code=he.status_code,
                content={"error": he.detail, "debug": {"trace": traceback.format_exc()}},
            )
        raise
    except Exception as e:
        logger.exception("[ERROR] /upload failed: %s", e)
        body = {"error": "Internal Server Error"}
        if DEBUG:
            body["debug"] = {"message": str(e), "trace": traceback.format_exc()}
        return JSONResponse(status_code=500, content=body)
