# fastapi_app.py  (runtime v3.9.0, AI-led YiJing)
# å˜æ›´è¦ç‚¹ï¼š
# - å°†â€œåˆ†æä¸è¯­è¨€ç”Ÿæˆâ€å°½é‡äº¤ç”± AIï¼›åç«¯ä»…æä¾›ç»“æ„ Schema ä¸æœ€å°æ¸…æ´—/å…œåº•ã€‚
# - äº”å®˜ç»†èŠ‚ï¼šæŒ‡ä»¤ä¸­å¼ºè°ƒâ€œå…ˆä»¥çˆ»åˆ¤è¯»äº”å®˜â†’å†ç»¼åˆä¸ºæ•´ä½“å¦è±¡ä¸ä¸‰è±¡(å§¿æ€/ç¥æƒ…/é¢å®¹)â€ã€‚
# - ä¸‰è±¡ç»„åˆä¸äº‹ä¸š/æ„Ÿæƒ…å»ºè®®å‡ç”± AI ç›´æ¥ç”Ÿæˆæ–‡æ¡ˆï¼›Python ä¸å†æ‹¼æ¥å¥å­æˆ–æ·»åŠ ç»æ–‡æ¨¡æ¿ã€‚
# - ä¿ç•™å‰ç«¯æ‰€éœ€å­—æ®µï¼šsummaryã€archetypeã€confidenceã€sectionsã€domainsã€meta.*ã€‚
# - ä»…åšè½»åº¦è§„èŒƒåŒ–ä¸å®¹é”™ï¼ˆå¦‚æŠŠ meta.triple_analysis å›å¡«åˆ° sectionsã€ç»„åˆæ ‡é¢˜ï¼‰ã€‚

import os, base64, json, logging, traceback, re
from typing import Dict, Any, List

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse, HTMLResponse, Response
from fastapi.middleware.cors import CORSMiddleware

from openai import OpenAI

RUNTIME_VERSION = "3.9.0-ai-led"
ANALYSIS_VERSION = os.getenv("ANALYSIS_VERSION", "390").strip()
SCHEMA_ID = "selfy.v3"
DEBUG = str(os.getenv("DEBUG","0")).strip() in ("1","true","True","YES","yes")

logging.basicConfig(level=logging.DEBUG if DEBUG else logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("selfy-ai")

app = FastAPI(title="Selfy AI - YiJing Analysis API", version=RUNTIME_VERSION)
app.add_middleware(CORSMiddleware, allow_origins=["*"] if DEBUG else ["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

try:
    client = OpenAI()
except Exception as e:
    logger.error("OpenAI client init failed: %s", e); client=None

BAGUA_SYMBOLS = {"è‰®":"å±±","ç¦»":"ç«","å…‘":"æ³½","ä¹¾":"å¤©","å¤":"åœ°","éœ‡":"é›·","å·½":"é£","å":"æ°´"}

# ----------------- åŸºç¡€å·¥å…· -----------------

def _to_data_url(content: bytes, content_type: str) -> str:
    return f"data:{content_type};base64,{base64.b64encode(content).decode('utf-8')}"


def _build_tools_schema() -> List[Dict[str, Any]]:
    """å®šä¹‰å”¯ä¸€å·¥å…·ï¼šsubmit_analysis_v3 â€”â€” è¾“å‡ºå¿…é¡»åŒ¹é…å‰ç«¯ç»“æ„ã€‚"""
    return [{
      "type":"function",
      "function":{
        "name":"submit_analysis_v3",
        "description":"Return end-user facing JSON for Selfy AI YiJing analysis.",
        "parameters":{
          "type":"object",
          "properties":{
            "summary":{"type":"string"},
            "archetype":{"type":"string"},
            "confidence":{"type":"number"},
            "sections":{"type":"object","properties":{"å§¿æ€":{"type":"string"},"ç¥æƒ…":{"type":"string"},"é¢ç›¸":{"type":"string"}},"required":["å§¿æ€","ç¥æƒ…","é¢ç›¸"],"additionalProperties":False},
            "domains":{"type":"array","items":{"type":"string"}},
            "meta":{"type":"object","additionalProperties":True}
          },
          "required":["summary","archetype","confidence","sections","domains"],
          "additionalProperties":False
        }
      }
    }]


def _json_hint() -> str:
    return (
        "åªä»¥ JSON object è¿”å›ï¼ˆå¿…é¡» JSONï¼‰ã€‚ç¤ºä¾‹:{"
        "\"summary\":\"æ•´ä½“å½¢è±¡æ²‰ç¨³ï¼Œå…¼å…·è¡¨è¾¾ä¸æ´å¯Ÿï¼Œé€‚åˆç¨³ä¸­æ±‚è¿›çš„èŠ‚å¥ã€‚\","
        "\"archetype\":\"ç¨³ä¸­å¸¦é”‹\","
        "\"confidence\":0.92,"
        "\"sections\":{\"å§¿æ€\":\"å§¿æ€ç«¯æ­£ï¼Œæ°”åœºç¨³é‡â€¦\",\"ç¥æƒ…\":\"ç¥æƒ…è‡ªè‹¥ï¼Œç›®å…‰ä¸“æ³¨â€¦\",\"é¢ç›¸\":\"é¢éƒ¨è½®å»“åˆ†æ˜ï¼Œäº”å®˜åè°ƒâ€¦\"},"
        "\"domains\":[\"é‡‘é’±ä¸äº‹ä¸š\",\"é…å¶ä¸æ„Ÿæƒ…\"],"
        "\"meta\":{"
            "\"triple_analysis\":{"
                "\"å§¿æ€\":{\"è¯´æ˜\":\"è‚©èƒŒæŒºç›´ï¼Œé‡å¿ƒç¨³å®š\",\"å¦è±¡\":\"è‰®\",\"è§£è¯»\":\"æ­¢è€Œæœ‰åº¦ï¼Œç¨³ä¸­æ±‚è¿›\",\"æ€§æ ¼å€¾å‘\":\"é‡è§†åŸåˆ™ï¼Œè¡Œäº‹æœ‰èŠ‚åˆ¶\"},"
                "\"ç¥æƒ…\":{\"è¯´æ˜\":\"çœ¼ç¥ä¸“æ³¨ï¼Œè¡¨æƒ…æ·¡å®š\",\"å¦è±¡\":\"ç¦»\",\"è§£è¯»\":\"æ´å¯Ÿç»†è‡´ï¼Œè¡¨è¾¾æ¸…æ™°\",\"æ€§æ ¼å€¾å‘\":\"é€»è¾‘æ€§å¼º\"},"
                "\"é¢å®¹\":{\"è¯´æ˜\":\"ä¸‹é¢Œçº¿æ¡æ¸…æ™°ï¼Œé¢§éª¨é€‚ä¸­\",\"å¦è±¡\":\"å…‘\",\"è§£è¯»\":\"æ²Ÿé€šé¡ºç•…ï¼Œæƒ…æ„Ÿå¤–éœ²\",\"æ€§æ ¼å€¾å‘\":\"å¹³æ˜“è¿‘äºº\"}"
            "},"
            "\"face_parts\":{"
                "\"çœ‰\":{\"ç‰¹å¾\":\"çœ‰å½¢å¹³ç›´\",\"å¦è±¡\":\"å·½\",\"è§£è¯»\":\"æ¡ç†åˆ†æ˜ï¼Œåˆ¤æ–­åŠ›å¼º\"},"
                "\"çœ¼\":{\"ç‰¹å¾\":\"åŒçœ¼æœ‰ç¥\",\"å¦è±¡\":\"ç¦»\",\"è§£è¯»\":\"æ´å¯ŸåŠ›é«˜ï¼Œå–„äºè¡¨è¾¾\"},"
                "\"é¼»\":{\"ç‰¹å¾\":\"é¼»æ¢æŒºç›´\",\"å¦è±¡\":\"è‰®\",\"è§£è¯»\":\"ç¨³å®ˆæœ¬åˆ†ï¼Œé‡è¾¹ç•Œ\"},"
                "\"å˜´\":{\"ç‰¹å¾\":\"å”‡å½¢å¯¹ç§°\",\"å¦è±¡\":\"å…‘\",\"è§£è¯»\":\"ä¹äºæ²Ÿé€šï¼Œæƒ…æ„ŸçœŸæŒš\"},"
                "\"é¢§/ä¸‹å·´\":{\"ç‰¹å¾\":\"é¢§éª¨é€‚ä¸­ï¼Œä¸‹å·´åœ†æ¶¦\",\"å¦è±¡\":\"å¤\",\"è§£è¯»\":\"æ‰¿è½½åŠ›å¼ºï¼Œå†…æ•›ç¨³é‡\"}"
            "},"
            "\"overview\":\"ç»“åˆå§¿æ€ã€ç¥æƒ…ä¸é¢å®¹çš„å¦è±¡åˆ†æï¼Œæ­¤äººå¤–åœ¨ç¨³å¥ï¼Œå†…åœ¨å…¼å…·æ´å¯Ÿä¸æ²Ÿé€šèƒ½åŠ›ï¼Œè¡Œäº‹æœ‰åˆ†å¯¸ä¸”èƒ½åœ¨éœ€è¦æ—¶æœæ–­æ¨è¿›ï¼Œé€‚åˆåœ¨å¤šå˜ç¯å¢ƒä¸­ä¿æŒç¨³å®šå¹¶åˆ›é€ æœºé‡ã€‚\","
            "\"domains_detail\":{"
                "\"é‡‘é’±ä¸äº‹ä¸š\":\"è¿‘æœŸäº‹ä¸šå‘å±•ç¨³ä¸­æœ‰å‡ï¼Œå®œå·©å›ºç°æœ‰æˆæœï¼ŒåŒæ—¶é€æ­¥å¼€æ‹“æ–°é¢†åŸŸï¼Œä¿æŒä¿¡æ¯é€šç•…ä»¥åº”å¯¹å˜åŒ–ã€‚\","
                "\"é…å¶ä¸æ„Ÿæƒ…\":\"æ„Ÿæƒ…å…³ç³»ç¨³å®šä¸”æœ‰æ·±åº¦äº¤æµï¼Œé€‚åˆå®‰æ’å…±åŒæ´»åŠ¨å¢åŠ äº’åŠ¨é¢‘ç‡ï¼Œé¿å…å› å¿™ç¢Œè€Œå¿½è§†å½¼æ­¤æ„Ÿå—ã€‚\""
            "},"
            "\"confidence_breakdown\":{"
                "\"å›¾åƒæ¸…æ™°åº¦\":0.85,"
                "\"å¦è±¡ä¸€è‡´æ€§\":0.9,"
                "\"ç‰¹å¾æ˜¾è‘—æ€§\":0.88"
            "}"
        "}"
        "}"
    )

# ----------------- Promptï¼ˆAIä¸»å¯¼ï¼‰ -----------------

def _prompt_for_image_ai_led():
    sys = (
      "ä½ æ˜¯ Selfy AI çš„æ˜“ç»è§‚ç›¸åŠ©æ‰‹ã€‚\n"
      "ç›®æ ‡ï¼šç”±ä½ (æ¨¡å‹)äº§å‡ºå…¨éƒ¨åˆ†æä¸è¯­è¨€ï¼Œæˆ‘ä»¬(åç«¯)åªåšç»“æ„çº¦æŸã€‚\n"
      "æ‰€æœ‰è¾“å‡ºå¿…é¡»ç¬¦åˆ Schemaï¼Œå¹¶ä¸”åŒ…å«ä»¥ä¸‹å¿…éœ€å­—æ®µï¼Œå¦åˆ™è§†ä¸ºä¸åˆæ ¼ï¼š\n"
      "1) summaryï¼š20â€“50å­—ç»¼åˆæ€§æ ¼å°è±¡ã€‚\n"
      "2) archetypeï¼š2â€“5å­—ä¸­æ–‡äººæ ¼æ ‡ç­¾ï¼Œç¦æ­¢æ˜¯å¦åæˆ–å¦è±¡ç»„åˆã€‚\n"
      "3) sectionsï¼šå§¿æ€ã€ç¥æƒ…ã€é¢ç›¸ï¼Œå„æœ‰è¯´æ˜ã€å¦è±¡ã€è§£è¯»ã€æ€§æ ¼å€¾å‘ã€‚\n"
      "4) meta.face_partsï¼šè‡³å°‘åŒ…å«çœ‰ã€çœ¼ã€é¼»ã€å˜´ã€é¢§/ä¸‹å·´ 5 é¡¹ï¼Œæ¯é¡¹å«ç‰¹å¾ã€å¦è±¡ã€è§£è¯»ï¼Œå¦è±¡éœ€ç»“åˆçˆ»åˆ†æã€‚\n"
      "5) meta.overviewï¼š90â€“150å­—ï¼Œç»¼åˆä¸‰è±¡ä¸äº”å®˜åˆ†ææˆå®Œæ•´æ€§æ ¼ä¸é£æ ¼è¯´æ˜ã€‚\n"
      "6) domainsï¼š['é‡‘é’±ä¸äº‹ä¸š','é…å¶ä¸æ„Ÿæƒ…']ã€‚\n"
      "7) meta.domains_detailï¼šæ¯é¡¹ 60â€“90å­—ï¼ŒåŒ…å«å½“å‰çŠ¶æ€ä¸å¯æ‰§è¡Œå»ºè®®ã€‚\n"
      "8) confidenceï¼š0â€“1æµ®ç‚¹ã€‚\n"
      "9) meta.confidence_breakdownï¼š{å›¾åƒæ¸…æ™°åº¦, å¦è±¡ä¸€è‡´æ€§, ç‰¹å¾æ˜¾è‘—æ€§} å„0â€“1å€¼ï¼Œå¹¶é™„ç®€çŸ­è§£é‡Šã€‚\n"
      "10) meta.overview_cardï¼šæ ‡é¢˜=å¦è±¡ç»„åˆï¼Œsummary=ç®€è¿°ï¼Œå¯ä¸meta.overviewä¸€è‡´ã€‚\n"
      "æ–‡é£ï¼šèåˆæ˜“ç»æœ¯è¯­ä¸ç™½è¯è§£é‡Šï¼Œé¿å…æ¨¡æ¿åŒ–ï¼Œç¦æ­¢ä¸å›¾åƒæ— å…³çš„æ¨æµ‹ã€‚\n"
      + _json_hint()
    )
    user = "è¯·å¯¹è¾“å…¥äººåƒè¿›è¡ŒAIä¸»å¯¼çš„æ˜“ç»è§‚ç›¸åˆ†æï¼Œå¹¶ä¸¥æ ¼ä»¥JSONé€šè¿‡å·¥å…·å‡½æ•°submit_analysis_v3è¿”å›ï¼Œç¼ºä»»ä½•å¿…éœ€å­—æ®µè§†ä¸ºä¸åˆæ ¼è¾“å‡ºã€‚"
    return [{"role":"system","content":sys},{"role":"user","content":user}]

# ----------------- è½»åº¦æ¸…æ´— / å…œåº• -----------------

_DOMAIN_LEADS = r"(åœ¨(é‡‘é’±ä¸äº‹ä¸š|é…å¶ä¸æ„Ÿæƒ…|äº‹ä¸š|æ„Ÿæƒ…)(æ–¹é¢|ä¸­|é‡Œ)?|ç›®å‰|è¿‘æœŸ|å½“ä¸‹)"
_STOPWORDS = r"(å§¿æ€|ç¥æƒ…|é¢å®¹|æ•´ä½“|æ°”è´¨|å½¢è±¡|ç»™äººä»¥|ä¸€ç§|ä»¥åŠ|å¹¶ä¸”|è€Œä¸”|æ›´æ˜¾|æ˜¾å¾—|å±•ç°å‡º|æµéœ²å‡º|é€éœ²å‡º)"

def _depronoun(s: str) -> str:
    if not isinstance(s, str): return s
    s = s.strip()
    s = re.sub(r"^(ä»–|å¥¹|TA|ä½ |å¯¹æ–¹|å…¶)(çš„)?[ï¼Œã€ï¼š ]*", "", s)
    s = re.sub(r"^(åœ¨(äº‹ä¸š|æ„Ÿæƒ…|ç”Ÿæ´»)[ä¸Šä¸­]|ç›®å‰|è¿‘æœŸ)[ï¼Œã€ï¼š ]*", "", s)
    return s

def _neutralize(s: str) -> str:
    if not isinstance(s, str): return s
    s = s.strip()
    s = re.sub(r"(ä»–|å¥¹|TA|å¯¹æ–¹|å…¶)(çš„)?", "", s)
    s = re.sub(_DOMAIN_LEADS + r"[ï¼Œã€ï¼š ]*", "", s)
    s = re.sub(r"(å¯èƒ½|æˆ–è®¸|ä¹Ÿè®¸)[ï¼Œã€ ]*", "", s)
    s = re.sub(r"[ï¼›;]+", "ï¼›", s)
    s = re.sub(r"[ï¼Œ,]{2,}", "ï¼Œ", s)
    return s.strip("ï¼›ï¼Œã€‚ ")


def _deep_clean(x):
    if isinstance(x, dict):
        return {k: _deep_clean(v) for k, v in x.items()}
    if isinstance(x, list):
        return [_deep_clean(v) for v in x]
    if isinstance(x, str):
        return _neutralize(_depronoun(x))
    return x


def _ensure_sections(out: Dict[str,Any]) -> None:
    """è‹¥ sections ä¸ºç©ºï¼Œåˆ™å°è¯•ä» meta.triple_analysis å›å¡«ã€‚"""
    sec = out.get("sections") or {}
    meta = out.get("meta") or {}
    ta = (meta.get("triple_analysis") or {}) if isinstance(meta, dict) else {}
    if not sec or not all(k in sec and isinstance(sec[k], str) and sec[k].strip() for k in ("å§¿æ€","ç¥æƒ…","é¢ç›¸")):
        out["sections"] = {
            "å§¿æ€": (ta.get("å§¿æ€") or {}).get("è§£è¯»", ""),
            "ç¥æƒ…": (ta.get("ç¥æƒ…") or {}).get("è§£è¯»", ""),
            "é¢ç›¸": (ta.get("é¢å®¹") or {}).get("è§£è¯»", ""),
        }


def _set_combo_title(out: Dict[str,Any]) -> None:
    """æ ¹æ®ä¸‰è±¡å¦è±¡ç”Ÿæˆç»„åˆæ ‡é¢˜ï¼Œè‹¥ AI å·²åœ¨ meta.overview/title ç»™å‡ºï¼Œåˆ™ä¸è¦†ç›–ã€‚"""
    meta = out.setdefault("meta", {})
    ta = meta.get("triple_analysis") or {}
    hexes = [ (ta.get("å§¿æ€") or {}).get("å¦è±¡",""), (ta.get("ç¥æƒ…") or {}).get("å¦è±¡",""), (ta.get("é¢å®¹") or {}).get("å¦è±¡","") ]
    hexes = [h for h in hexes if h]
    if hexes:
        meta.setdefault("combo_title", " + ".join(hexes))
        meta.setdefault("overview_card", {"title": f"ğŸ”® å¦è±¡ç»„åˆï¼š{' + '.join(hexes)}", "summary": (meta.get("overview") or "").strip()})


def _coerce_output(data: Dict[str,Any]) -> Dict[str,Any]:
    out = dict(data or {})
    out.setdefault("summary", "")
    out.setdefault("archetype", "")
    try:
        out["confidence"] = float(out.get("confidence", 0.0))
    except Exception:
        out["confidence"] = 0.0
    out.setdefault("sections", {"å§¿æ€":"","ç¥æƒ…":"","é¢ç›¸":""})
    out.setdefault("domains", [])
    out.setdefault("meta", {})

    # è½»åº¦æ¸…æ´—
    out = _deep_clean(out)

    # å…œåº•ï¼šä» triple_analysis å›å¡« sectionsã€ç”Ÿæˆç»„åˆæ ‡é¢˜å¡ç‰‡
    _ensure_sections(out)
    _set_combo_title(out)

    return out


# ----------------- è·¯ç”± -----------------

@app.get("/health")
def health(): return {"status":"ok"}

@app.get("/", include_in_schema=False)
def root():
    return HTMLResponse("<h3>Selfy AI</h3><a href='/docs'>/docs</a> Â· <a href='/mobile'>/mobile</a>")

@app.head("/", include_in_schema=False)
def root_head():
    return Response(status_code=200)

@app.get("/version")
def version(): return {"runtime":RUNTIME_VERSION,"analysis":ANALYSIS_VERSION,"schema":SCHEMA_ID,"debug":DEBUG}

@app.get("/mobile", include_in_schema=False)
def mobile():
    path = os.path.join(os.path.dirname(__file__), "index_mobile.html")
    try:
        html = open(path, "r", encoding="utf-8").read()
    except Exception as e:
        return HTMLResponse(f"<pre>index_mobile.html not found: {e}</pre>", status_code=500)
    return HTMLResponse(html)


# ----------------- OpenAI è°ƒç”¨ -----------------

def _call_openai(messages):
    if client is None:
        raise RuntimeError("OpenAI client not initialized")
    return client.chat.completions.create(
        model="gpt-4o",
        temperature=0.4,
        tools=_build_tools_schema(),
        tool_choice={"type":"function","function":{"name":"submit_analysis_v3"}},
        response_format={"type":"json_object"},
        messages=messages
    )


def _call_gpt_tool_with_image(data_url: str) -> Dict[str,Any]:
    messages = _prompt_for_image_ai_led()
    messages[-1]["content"] = [
        {"type":"text","text":messages[-1]["content"]},
        {"type":"image_url","image_url":{"url":data_url}}
    ]
    resp = _call_openai(messages)
    choice = resp.choices[0]
    tool_calls = getattr(choice.message, "tool_calls", None)
    if tool_calls:
        args = json.loads(tool_calls[0].function.arguments)
    else:
        content = getattr(choice.message, "content", None)
        if isinstance(content, str) and content.strip().startswith("{"):
            args = json.loads(content)
        else:
            raise RuntimeError("Model did not return tool_calls.")
    return {"tool_args": args, "oai_raw": resp if DEBUG else None}


# ----------------- ä¸Šä¼ æ¥å£ -----------------

@app.post("/upload")
async def upload(file: UploadFile = File(...)):
    try:
        if not file: raise HTTPException(400,"No file")
        ct = file.content_type or ""
        if not ct.startswith("image/"): raise HTTPException(415,f"Unsupported content type: {ct}")
        raw = await file.read()
        if not raw: raise HTTPException(400,"Empty file")
        if len(raw) > 15*1024*1024: raise HTTPException(413,"File too large (>15MB)")

        data_url = _to_data_url(raw, ct)
        logger.info("[UPLOAD] %s %dB %s", file.filename, len(raw), ct)

        result = _call_gpt_tool_with_image(data_url)
        tool_args = result["tool_args"]
        final_out = _coerce_output(tool_args)

        if DEBUG:
            meta = final_out.setdefault("meta",{}).setdefault("debug",{})
            meta["file_info"]={"filename":file.filename,"content_type":ct,"size":len(raw)}
            try:
                meta["oai_choice_finish_reason"]=result["oai_raw"].choices[0].finish_reason
            except Exception:
                meta["oai_choice_finish_reason"]="n/a"

        return JSONResponse(content=final_out, status_code=200)
    except HTTPException as he:
        if DEBUG:
            return JSONResponse(status_code=he.status_code, content={"error":he.detail,"debug":{"trace":traceback.format_exc()}})
        raise
    except Exception as e:
        logging.exception("upload failed: %s", e)
        body={"error":"Internal Server Error"}
        if DEBUG: body["debug"]={"message":str(e),"trace":traceback.format_exc()}
        return JSONResponse(status_code=500, content=body)
